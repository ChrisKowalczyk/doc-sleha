<!ENTITY def-existing-cluster 
'  The term <quote>existing cluster</quote> is used to refer to any
    cluster that consists of at least one node. Existing clusters have a basic
    &corosync; configuration that defines the communication channels, but
    they do not necessarily have resource configuration yet.'>
    
 <!ENTITY def-multicast
 '  A technology used for a one-to-many communication within a network that
    can be used for cluster communication. &corosync; supports both
    multicast and unicast.'>
   
<!ENTITY def-unicast
'  A technology for sending messages to a single network destination.
    &corosync; supports both multicast and unicast. In &corosync;, unicast
    is implemented as UDP-unicast (UDPU).'>
   
<!ENTITY def-mcastaddr
'  IP address to be used for multicasting by the &corosync; executive. The IP
   address can either be IPv4 or IPv6. '>   
   
<!ENTITY def-mcastport
'  The port to use for cluster communication.'>   

<!ENTITY def-bindnetaddr
'The network address the &corosync; executive should bind to. '>

<!ENTITY def-rrp 
' Allows the  use of multiple redundant local area networks for resilience against
   partial or total network faults. This way, cluster communication can
   still be kept up as long as a single network is operational.
   &corosync; supports the Totem Redundant Ring Protocol.'>
   
 <!ENTITY def-csync2 
 'A synchronization tool that can be used to replicate configuration files
    across all nodes in the cluster, and even across &geo; clusters.'>  
    
<!ENTITY def-conntrack
'Allow interaction with the in-kernel connection tracking system for
    enabling <emphasis>stateful</emphasis> packet inspection for iptables. Used
    by the &hasi; to synchronize the connection status between cluster
    nodes.'>    
    
<!ENTITY def-ay
'&ay; is a system for installing one or more &sle; systems automatically
    and without user intervention. '>    
    

<!ENTITY maint-mode-basics
' <para>Every now and then, you will need to perform testing or maintenance tasks on individual
   cluster components or the whole cluster&mdash;be it changing the cluster configuration,
   updating software packages for individual nodes, or upgrading the cluster to a higher product
   version. </para>'>
   
   <!ENTITY warning-maint-mode
   '<warning>
   <title>Risk of Data Loss</title>
   <para>If you need to execute any testing or maintenance tasks while services are running under
    cluster control, make sure to follow this outline:</para>
   <orderedlist>
    <listitem>
     <para>Before you start, set the individual resource, node or the whole cluster to maintenance
      mode. This helps to avoid unwanted side effects like resources not starting in an orderly
      fashion, the risk of unsynchronized CIBs across the cluster nodes or data loss. </para>
    </listitem>
    <listitem>
     <para>Execute your maintenance task or tests.</para>
    </listitem>
    <listitem>
     <para>After you have finished, remove the maintenance mode to start normal cluster
      operation.</para>
    </listitem>
   </orderedlist>
  </warning>'>
  
 <!ENTITY booth-port
 'The port to be used for communication between the booth instances at each
 site.'>
   
 <!ENTITY booth-transport
 'The transport protocol used for communication between the sites. '>
 
 <!ENTITY booth-site
 'The IP address used for the &boothd; on a site. '>
 
 <!ENTITY booth-arbitrator
' The IP address of the machine to use as arbitrator. '>

 <!ENTITY booth-ticket
 'The ticket to be managed by booth.'> 

<!ENTITY booth-ticket-expiry
'Defines the ticket&apos;s expiry time in seconds. A site that has been granted a ticket will 
renew the ticket regularly. If booth does not receive any information about renewal of the 
ticket within the defined expiry time, the ticket will be revoked and granted to another site. 
If no expiry time is specified, the ticket will expire after <literal>600</literal> seconds 
by default. '>

<!ENTITY booth-ticket-timeout
'Defines a timeout period in seconds. After that time, booth will resend packets if there was 
an insufficient number of replies. The timeout defined should be long enough to allow packets 
to reach other members. <remark>taroth 2014-08-21: dejan, which members? 
raft cluster members?=cluster sites?</remark>'>

<!ENTITY booth-ticket-retries
'Defines how many times booth retries sending packets before giving up waiting 
for confirmation by other sites. Values smaller than <literal>3</literal> are illegal.
<remark>taroth 2014-08-21: dejan, what does "illegal" mean here? are not
accepted by booth? must not be used? </remark>'>

<!ENTITY booth-ticket-renewal
'Sets the ticket renewal frequency period. Ticket renewal occurs every half expiry 
time by default. If the network reliability is often reduced over prolonged periods, 
it is advisable to renew more often. Before every renewal the 
<literal>before-acquire-handler</literal> is run. 
This parameter then doubles as a local cluster monitor interval. 
<remark>taroth 2014-08-21: dejan, no idea what the last sentence
is trying to say...? could you explain or rephrase this, please?</remark>'>

<!ENTITY booth-ticket-handler-1
'If set, the specified command will be called before &boothd; tries to acquire 
or renew a ticket. On exit code other than <literal>0</literal>,
&boothd; relinquishes the ticket.'>

<!ENTITY booth-ticket-handler-2
'<para>Thus it is possible to ensure whether the services and its dependencies 
protected by the ticket are in good shape at this site. For instance, if a service in the
dependency-chain has a failcount of <literal>INFINITY</literal> on all 
available nodes, the service will be unable to run. In that case, it is of 
no use to claim the ticket. </para>
<para> The <filename>service-runnable</filename> script referenced here is included in the
 product is an example with which you can test whether a &pace; resource can be
 started.???</para>'>
 
 <!ENTITY booth-multi-tenancy
 ' For setups including multiple &geo; clusters, it is possible to
    <quote>share</quote> the same arbitrator (as of &productname; 12). By
   providing several booth configuration files, you can start multiple booth
   instances on the same arbitrator, with each booth instance running on a
   different port. That way, you can use <emphasis>one</emphasis> machine to
   serve as arbitrator for <emphasis>different</emphasis> &geo; clusters. '>
