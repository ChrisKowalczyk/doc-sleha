<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd" [
 <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
 <!ENTITY % entities SYSTEM "entity-decl.ent">
 %entities;
]>

<chapter id="cha.ha.configuration.basics">
 <title>Configuration and Administration Basics</title>
 <abstract>
  <para>
   The main purpose of an HA cluster is to manage user services. Typical
   examples of user services are an Apache web server or a database. From
   the user's point of view, the services do something specific when ordered
   to do so. To the cluster, however, they are just resources which may be
   started or stopped&mdash;the nature of the service is irrelevant to the
   cluster.
  </para>

  <para>
   In this chapter, we will introduce some basic concepts you need to know
   when configuring resources and administering your cluster. The following
   chapters show you how to execute the main configuration and
   administration tasks with each of the management tools the &hasi;
   provides.
  </para>
 </abstract>
 <remark>taroth 2010-02-19: todo - for each section/topic add xrefs to the
 following chapters (GUI, HAWK, CLI)</remark>
 <sect1 id="sec.ha.configuration.basics.global">
  <title>Global Cluster Options</title>

  <para> Global cluster options control how the cluster behaves when confronted
   with certain situations. They are grouped into sets and can be viewed and
   modified with the cluster management tools like &hbgui; and
   <command>crm_mon</command>. The predefined values can be kept in most cases.
   However, to make key functions of your cluster work correctly, you need to
   adjust the following parameters after basic cluster setup: </para>

  <itemizedlist>
   <listitem>
    <para>
     <xref linkend="sec.ha.configuration.basics.global.quorum"
      xrefstyle="select:title"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="sec.ha.configuration.basics.global.stonith"
      xrefstyle="select:title"/>
    </para>
   </listitem>
  </itemizedlist>
  <remark>taroth 2010-02-24: todo - mention further situations/usecases as
   explained by lmb</remark>
    <sect2 id="sec.ha.configuration.basics.global.quorum">
   <title>Option <literal>no-quorum-policy</literal></title>
   <para>
    This global option defines what to do when the cluster does not have
    quorum.
   </para>
   <para>
    Allowed values are:
   </para>
   <variablelist>
    <varlistentry>
     <term><literal>ignore</literal></term>
     <listitem>
      <para>The quorum state does not influence the cluster behavior at all,
       resource management is continued. </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><literal>freeze</literal></term>
     <listitem>
      <para>If quorum is lost, the cluster freezes. Resource management is
       continued: running resources are not stopped (but possibly restarted in
       response to monitor events), but no further resources are started within
       the affected partition. </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><literal>stop</literal> (default value)</term>
     <listitem>
      <para>If quorum is lost, all resources in the affected cluster partition
       are stopped in an orderly fashion. </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><literal>suicide</literal>
      </term>
     <listitem>
      <para>Fence all nodes in the affected cluster partition. </para>
     </listitem>
    </varlistentry>
   </variablelist>
   
   <para>
    If your cluster only consists of 2 nodes, set
    <literal>no-quorum-policy</literal> to <literal>ignore</literal> because
    otherwise the cluster will never have quorum (which is a prerequisite
    for fencing).
   </para>
   <remark>taroth 2010-02-23: todo - add xrefs to GUI/CLI chapters</remark>
  </sect2>

  <sect2 id="sec.ha.configuration.basics.global.stonith">
   <title>Option <literal>stonith-enabled</literal></title>
   <para> This global option defines if to apply fencing, allowing &stonith;
    devices to shoot failed nodes and nodes with resources that cannot be
    stopped. By default, this global option is set to <literal>true</literal>,
    because for normal cluster operation it is necessary to use &stonith;
    devices. According to the default value, the cluster will refuse to start
    any resources if no &stonith; resources have been defined. </para>
   <para> If you need to disable fencing for any reasons, set
     <literal>stonith-enabled</literal> to <literal>false</literal>. </para>
   <remark>taroth 2010-02-23: todo - add xrefs to GUI/CLI chapters</remark>

   <para> For an overview of all global cluster options and their default
    values, see <citetitle>Pacemaker 1.0&mdash;Configuration
     Explained</citetitle>, available from <ulink
     url="http://clusterlabs.org/wiki/Documentation"/>. Refer to section
     <citetitle>Available Cluster Options</citetitle>. </para>
  </sect2>

 </sect1>
 <sect1 id="sec.ha.configuration.basics.resources">
  <title>Cluster Resources</title>

  <para>
   As a cluster administrator, you need to create cluster resources for
   every resource or application you run on servers in your cluster. Cluster
   resources can include Web sites, e-mail servers, databases, file systems,
   virtual machines, and any other server-based applications or services you
   want to make available to users at all times.
  </para>

  <sect2 id="sec.ha.configuration.basics.resources.management">
   <title>Resource Management</title>
<!--taroth 2010-02-23: fix for bnc#578583-->
   <para>
    Before you can use a resource in the cluster, it must be set up. For
    example, if you want to use an Apache server as a cluster resource, set
    up the Apache server first and complete the Apache configuration before
    starting the respective resource in your cluster.
   </para>
   <note>
    <title>Do Not Touch Services Used by High Availability</title>
    <para>
     When used by &ha;, the service should not be touched by other means.
     This means that it should not be started or stopped on boot, reboot, or
     manually. However, if you want to check if the service is configured
     properly, start it manually, but make sure that it is stopped again
     before &ha; takes over.
    </para>
   </note>
   <para>
    After having configured the resources in the cluster, use the cluster
    management tools to start, stop, clean up, remove or migrate any
    resources manually. For details how to do so, refer to
    <xref
     linkend="cha.ha.configuration.gui"/> or to
    <xref
     linkend="cha.ha.manual_config"/>.
   </para>
  </sect2>

  <sect2 id="sec.ha.configuration.basics.resources.types">
   <title>Types of Resources</title>
   <para>
    The following types of resources can be created:
   </para>
   <variablelist>
    <varlistentry>
     <term>Primitives</term>
     <listitem>
      <para>
       A primitive resource, the most basic type of a resource.
      </para>
      <para>
       Learn how to create primitive resources with the GUI in
       <xref
        linkend="pro.ha.config.gui.primitives"/>. If you prefer
       the command line approach, see
       <xref linkend="sec.ha.manual_config.create"/>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Groups</term>
     <listitem>
      <para>
       Groups contain a set of resources that need to be located together,
       start sequentially and stop in the reverse order. For more
       information, refer to
       <xref
        linkend="sec.ha.configuration.basics.resources.advanced.groups"
       />.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Clones</term>
     <listitem>
      <para>
       Clones are resources that can be active on multiple hosts. Any
       resource can be cloned, provided the respective resource agent
       supports it. For more information, refer to
       <xref
        linkend="sec.ha.configuration.basics.resources.advanced.clones"
       />.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Masters</term>
     <listitem>
      <para>
       Masters are a special type of a clone resources, they can have
       multiple modes. For more information, refer to
       <xref
        linkend="sec.ha.configuration.basics.resources.advanced.masters"
       />.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 id="sec.ha.configuration.basics.resources.advanced">
   <title>Advanced Resource Types</title>
   <para>
    Whereas primitives are the simplest kind of resources and therefore easy
    to configure, you will probably also need more advanced resources types
    for cluster configuration, such as groups, clones or masters.
   </para>
   <sect3 id="sec.ha.configuration.basics.resources.advanced.groups">
    <title>Groups</title>
    <para>
     Some cluster resources are dependent on other components or resources,
     and require that each component or resource starts in a specific order
     and runs together on the same server. To simplify this configuration,
     you can use groups.
    </para>
    <para>
     Groups have the following properties:
    </para>
    <variablelist>
     <varlistentry>
      <term>Starting and Stopping</term>
      <listitem>
       <para>
        Resources are started in the order they appear in and stopped in the
        reverse order which they appear in.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Dependency</term>
      <listitem>
       <para>
        If a resource in the group cannot run anywhere, then none of the
        resources located after that resource in the group is allowed to
        run.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Contents</term>
      <listitem>
       <para>
        Groups may only contain a collection of primitive cluster resources.
        Groups must contain at least one resource, otherwise the
        configuration is not valid. To refer to the child of a group
        resource, use the child’s ID instead of the group’s.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Constraints</term>
      <listitem>
       <para>
        Although it is possible to reference the group’s children in
        constraints, it is usually preferable to use the group’s name
        instead.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Stickiness</term>
      <listitem>
       <para>
        Stickiness is additive in groups. Every <emphasis>active</emphasis>
        member of the group will contribute its stickiness value to the
        group’s total. So if the default
        <literal>resource-stickiness</literal> is <literal>100</literal> and
        a group has seven members (ﬁve of which are active), then the
        group as a whole will prefer its current location with a score of
        <literal>500</literal>.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Resource Monitoring</term>
      <listitem>
       <para>
        To enable resource monitoring for a group, you must configure
        monitoring separately for each resource in the group that you want
        monitored.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Learn how to create groups with the GUI in
     <xref
     linkend="pro.ha.config.gui.group"/>. If you prefer the
     command line approach, see
     <xref linkend="sec.ha.manual_config.group"/>.
    </para>
   </sect3>
   <sect3 id="sec.ha.configuration.basics.resources.advanced.clones">
    <title>Clones</title>
    <para>
     You may want certain resources to run simultaneously on multiple nodes
     in your cluster. To do this you must configure a resource as a clone.
     Examples of resources that might be configured as clones include
     &stonith; and cluster file systems like OCFS2. You can clone any
     resource provided it is supported by the resource’s Resource Agent.
     Clone resources may even be configured differently depending on which
     nodes they are hosted.
    </para>
    <para>
     There are three types of resource clones:
    </para>
    <variablelist>
     <varlistentry>
      <term>Anonymous Clones</term>
      <listitem>
       <para>
        These are the simplest type of clones. They behave identically
        anywhere they are running. Because of this, there can only be one
        instance of an anonymous clone active per machine.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Globally Unique Clones</term>
      <listitem>
       <para>
        These resources are distinct entities. An instance of the clone
        running on one node is not equivalent to another instance on another
        node; nor would any two instances on the same node be equivalent.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Stateful Clones</term>
      <listitem>
       <para>
        Active instances of these resources are divided into two states,
        active and passive. These are also sometimes referred to as primary
        and secondary, or master and slave. Stateful clones can be either
        anonymous or globally unique. See also
        <xref
         linkend="sec.ha.configuration.basics.resources.advanced.masters"
        />.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Clones must contain exactly one group or one regular resource.
    </para>
    <para>
     When configuring resource monitoring or constraints, masters have
     different requirements than simple resources. For details, see
     <citetitle>Pacemaker 1.0&mdash;Configuration Explained</citetitle>,
     available from
     <ulink url="http://clusterlabs.org/wiki/Documentation"/>. Refer to
     section <citetitle>Clones - Resources That Should be Active on Multiple
     Hosts</citetitle>.
    </para>
    <para>
     Learn how to create clones with the GUI in
     <xref
     linkend="pro.ha.config.gui.clone"/>. If you prefer the
     command line approach, see
     <xref linkend="sec.ha.manual_config.clone"/>.
    </para>
   </sect3>
   <sect3 id="sec.ha.configuration.basics.resources.advanced.masters">
    <title>Masters</title>
    <para>
     Masters are a specialization of clones that allow the instances to be
     in one of two operating modes (<literal>master</literal> or
     <literal>slave</literal>). Masters must contain exactly one group or
     one regular resource.
    </para>
    <para>
     When configuring resource monitoring or constraints, masters have
     different requirements than simple resources. For details, see
     <citetitle>Pacemaker 1.0&mdash;Configuration Explained</citetitle>,
     available from
     <ulink url="http://clusterlabs.org/wiki/Documentation"/>. Refer to
     section <citetitle>Multi-state - Resources That Have Multiple
     Modes</citetitle>.
    </para>
   </sect3>
  </sect2>

  <sect2 id="sec.ha.configuration.basics.resources.parameters">
   <title>Resource Parameters</title>
   <para>
    You can add or modify the following parameters for resources at any
    time:
   </para>
   <variablelist>
    <varlistentry>
     <term>Meta Attributes</term>
     <listitem>
      <para>
       Meta attributes are options you can add to a resource. They tell the
       CRM how to treat a specific resource. For an overview of the
       available meta attributes, their values and defaults, refer to
       <xref
        linkend="sec.ha.resources.options"/>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Instance Attributes</term>
     <listitem>
      <para>
       Instance attributes are parameters for certain resource classes that
       determine how they behave and which instance of a service they
       control. For more information, refer to
       <xref
        linkend="sec.ha.resources.instattributs"/>.
      </para>
      <para>
       Note that groups, clones and masters do not have instance attributes.
       However, any instance attributes set will be inherited by the
       group's, clone's or master's children.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Operations</term>
     <listitem>
      <para>
       The monitor operations added for a resource. These instruct the
       cluster to make sure that the resource is still healthy. Monitor
       operations can be added for all classes of resource agents. For more
       information, refer to
       <xref
        linkend="sec.ha.configuration.basics.monitoring"/>.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
 </sect1>
 <sect1 id="sec.ha.configuration.basics.monitoring">
  <title>Resource Monitoring</title>

  <para>
   If you want to ensure that a resource is running, you must configure
   resource monitoring for it.
  </para>

  <para>
   If the resource monitor detects a failure, the following takes place:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Log file messages are generated, according to the configuration
     specified in the <literal>logging</literal> section of
     <filename>/etc/corosync/corosync.conf</filename>. By default, the logs
     are written to syslog, usually <filename>/var/log/messages</filename>.
    </para>
   </listitem>
   <listitem>
    <para>
     The failure is reflected in the cluster management tools (&hbgui;,
     &hawk; <command>crm_mon</command>), and in the CIB status section.
    </para>
   </listitem>
   <listitem>
    <para>
     The cluster initiates noticeable recovery actions which may include
     stopping the resource to repair the failed state and restarting the
     resource locally or on another node. The resource also may not be
     restarted at all, depending on the configuration and state of the
     cluster.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   If you do not configure resource monitoring, resource failures after a
   successful start will not be communicated, and the cluster will always
   show the resource as healthy.
  </para>

  <para>
   Learn how to add monitor operations to resources with the GUI in
   <xref
    linkend="pro.ha.config.gui.operations"/>. If you prefer the
   command line approach, see
   <xref linkend="sec.ha.manual_config.monitor"/>.
  </para>
 </sect1>
 <sect1 id="sec.ha.configuration.basics.constraints">
  <title>Resource Constraints</title>

  <para>
   Having all the resources configured is only part of the job. Even if the
   cluster knows all needed resources, it might still not be able to handle
   them correctly. Resource constraints let you specify which cluster nodes
   resources can run on, what order resources will load, and what other
   resources a specific resource is dependent on.
  </para>

  <sect2 id="sec.ha.configuration.basics.constraints.types">
   <title>Types of Constraints</title>
   <para>
    There are three different kinds of constraints available:
   </para>
   <variablelist>
    <varlistentry>
     <term>Resource Location
    </term>
     <listitem>
      <para>
       Locational constraints that define on which nodes a resource may be
       run, may not be run or is preferred to be run.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Resource Collocation</term>
     <listitem>
      <para>
       Collocational constraints that tell the cluster which resources may
       or may not run together on a node.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Resource Order</term>
     <listitem>
      <para>
       Ordering constraints to define the sequence of actions.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <para>
    For more information on configuring constraints and detailed background
    information about the basic concepts of ordering and collocation, refer
    to the following documents available at
    <ulink
     url="http://clusterlabs.org/wiki/Documentation"/>:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <citetitle>Pacemaker 1.0&mdash;Configuration Explained</citetitle> ,
      chapter <citetitle>Resource Constraints</citetitle>
     </para>
    </listitem>
    <listitem>
     <para>
      <citetitle>Collocation Explained</citetitle>
     </para>
    </listitem>
    <listitem>
     <para>
      <citetitle>Ordering Explained</citetitle>
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Learn how to add the various kinds of constraints with the GUI in
    <xref
     linkend="sec.ha.configuration.constraints"/>. If you prefer
    the command line approach, see
    <xref linkend="sec.ha.manual_config.constraints"/>.
   </para>
  </sect2>

  <sect2 id="sec.ha.configuration.basics.constraints.scores">
   <title>Scores and Infinity</title>
   <para>
    When defining constraints, you also need to deal with scores. Scores of
    all kinds are integral to how the cluster works. Practically everything
    from migrating a resource to deciding which resource to stop in a
    degraded cluster is achieved by manipulating scores in some way. Scores
    are calculated on a per-resource basis and any node with a negative
    score for a resource cannot run that resource. After calculating the
    scores for a resource, the cluster then chooses the node with the
    highest score.
   </para>
   <para>
    <literal>INFINITY</literal> is currently deﬁned as
    <literal>1,000,000</literal>. Additions or subtractions with it follows
    the following 3 basic rules:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Any value + INFINITY = INFINITY
     </para>
    </listitem>
    <listitem>
     <para>
      Any value - INFINITY = -INFINITY
     </para>
    </listitem>
    <listitem>
     <para>
      INFINITY - INFINITY = -INFINITY
     </para>
    </listitem>
   </itemizedlist>
   <para>
    When defining resource constraints, you specify a score for each
    constraint. The score indicates the value you are assigning to this
    resource constraint. Constraints with higher scores are applied before
    those with lower scores. By creating additional location constraints
    with different scores for a given resource, you can specify an order for
    the nodes that a resource will fail over to.
   </para>
  </sect2>

  <sect2 id="sec.ha.configuration.basics.failover">
   <title>Failover Nodes</title>
   <para>
    A resource will be automatically restarted if it fails. If that cannot
    be achieved on the current node, or it fails <literal>N</literal> times
    on the current node, it will try to fail over to another node. Each time
    the resource fails, its failcount is raised. You can define a number of
    failures for resources (a <literal>migration-threshold</literal>), after
    which they will migrate to a new node. If you have more than two nodes
    in your cluster, the node a particular resource fails over to is chosen
    by the &ha; software.
   </para>
   <para>
    However, you can specify the node a resource will fail over to by
    configuring one or several location constraints and a
    <literal>migration-threshold</literal> for that resource. For detailed
    instructions how to achieve this with the GUI, refer to
    <xref
     linkend="sec.ha.configuration.failover"/>. If you prefer the
    command line approach, see
    <xref linkend="sec.ha.manual_config.failover"/>.
   </para>
   <example id="ex.ha.config.basics.failover">
    <title>Migration Threshold&mdash;Process Flow</title>
    <para>
     For example, let us assume you have configured a location constraint
     for resource <literal>r1</literal> to preferably run on
     <literal>node1</literal>. If it fails there,
     <literal>migration-threshold</literal> is checked and compared to the
     failcount. If failcount >= migration-threshold then the resource is
     migrated to the node with the next best preference.
    </para>
    <para>
     By default, once the threshold has been reached, the node will no
     longer be allowed to run the failed resource until the resource's
     failcount is reset. This can be done manually by the cluster
     administrator or by setting a <literal>failure-timeout</literal> option
     for the resource.
    </para>
    <para>
     For example, a setting of <literal>migration-threshold=2</literal> and
     <literal>failure-timeout=60s</literal> would cause the resource to
     migrate to a new node after two failures and potentially allow it to
     move back (depending on the stickiness and constraint scores) after one
     minute.
    </para>
   </example>
   <para>
    There are two exceptions to the migration threshold concept, occurring
    when a resource either fails to start or fails to stop:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Start failures set the failcount to <literal>INFINITY</literal> and
      thus always cause an immediate migration.
     </para>
    </listitem>
    <listitem>
     <para>
      Stop failures cause fencing (when <literal>stonith-enabled</literal>
      is set to <literal>true</literal> which is the default).
     </para>
     <para>
      In case there is no STONITH resource defined (or
      <literal>stonith-enabled</literal> is set to
      <literal>false</literal>), the resource will not migrate at all.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    For details on using migration thresholds and resetting failcounts,
    refer to <xref linkend="sec.ha.configuration.failover"/>. If you prefer
    the command line approach, see
    <xref linkend="sec.ha.manual_config.failover"
    />.
   </para>
  </sect2>

  <sect2 id="sec.ha.configuration.basics.failback">
   <title>Failback Nodes</title>
   <para>
    A resource might fail back to its original node when that node is back
    online and in the cluster. If you want to prevent a resource from
    failing back to the node it was running on prior to failover, or if you
    want to specify a different node for the resource to fail back to, you
    must change its <literal>resource stickiness</literal> value. You can
    either specify resource stickiness when you are creating a resource, or
    afterwards.
   </para>
   <para>
    Consider the following implications when specifying resource stickiness
    values:
   </para>
   <variablelist>
    <varlistentry>
     <term>Value is <literal>0</literal>:</term>
     <listitem>
      <para>
       <remark>taroth 090402: todo - explain better for next review - ygao: It defaults to the
       value of "default-resource-stickiness" which could be set in "CRM Config". And yes, that
       property defaults to be 0. </remark>
       This is the default. The resource will be placed optimally in the
       system. This may mean that it is moved when a <quote>better</quote>
       or less loaded node becomes available. This option is almost
       equivalent to automatic failback, except that the resource may be
       moved to a node that is not the one it was previously active on.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Value is greater than <literal>0</literal>:</term>
     <listitem>
      <para>
       The resource will prefer to remain in its current location, but may
       be moved if a more suitable node is available. Higher values indicate
       a stronger preference for a resource to stay where it is.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Value is less than <literal>0</literal>:</term>
     <listitem>
      <para>
       The resource prefers to move away from its current location. Higher
       absolute values indicate a stronger preference for a resource to be
       moved.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Value is <literal>INFINITY</literal>:</term>
     <listitem>
      <para>
       The resource will always remain in its current location unless forced
       off because the node is no longer eligible to run the resource (node
       shutdown, node standby, reaching the
       <literal>migration-threshold</literal>, or configuration change).
       This option is almost equivalent to completely disabling automatic
       failback.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Value is <literal>-INFINITY</literal>:</term>
     <listitem>
      <para>
       The resource will always move away from its current location.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
 </sect1>
 <sect1 id="sec.ha.configuration.basics.more">
  <title>For More Information</title>
  
  <variablelist>
   <varlistentry>
    <term><ulink url="http://clusterlabs.org/"/>
    </term>
    <listitem>
     <para>
      Home page of Pacemaker, the cluster resource manager shipped with the
      &hasi;.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><ulink url="http://linux-ha.org"/>
    </term>
    <listitem>
     <para>
      Home page of the The High Availability Linux Project.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><ulink url=" http://clusterlabs.org/wiki/Documentation"/>
    </term>
    <listitem>
     <para>
      <citetitle>CRM Command Line Interface</citetitle> : Introduction to
      the <command>crm</command> command line tool.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><ulink url=" http://clusterlabs.org/wiki/Documentation"/>
    </term>
    <listitem>
     <para>
      <citetitle>Pacemaker 1.0&mdash;Configuration Explained</citetitle> : Explains the
      concepts used to conﬁgure Pacemaker. Contains comprehensive and very
      detailed information for reference.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
</chapter>
