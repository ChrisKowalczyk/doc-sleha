<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:novdoc-profile.xsl"
type="text/xml" 
title="Profiling step"?>
<!DOCTYPE article PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN"
                      "novdocx.dtd"
[
<!ENTITY % NOVDOC.DEACTIVATE.IDREF "IGNORE">
<!ENTITY % entities SYSTEM "entity-decl.ent">
%entities;
]>
  <?provo dirname="iscsci_quick/"?>
  <article lang="en" id="art_ha_quick_iscsi">
    <?suse-quickstart version="1" color="suse" columns="no"?>
    <title>Highly Available iSCSI Storage with DRBD and Pacemaker</title>
    <subtitle><productname>&productname; &productnumber;</productname></subtitle>
    <articleinfo>
      <productname>&sle; &hasi; </productname>
      <productnumber>11 SP1</productnumber>
      <authorgroup>
        <author>
          <firstname>Florian</firstname>
          <surname>Haas</surname>
        </author>
        <author>
          <firstname>Tanja</firstname>
          <surname>Roth</surname>
        </author>
      </authorgroup>
    </articleinfo>
  
 <sect1 id="_introduction">
<title>Introduction</title>
<para>SCSI is an implementation of the SCSI protocol over IP. In iSCSI,
servers (targets) provide storage services to clients (initiators)
over IP based networks using SCSI semantics. On iSCSI initiator nodes,
logical units (LUs) appear like any other SCSI block device, where
they may be partitioned, used to hold filesystem storage, used to
contain raw data, etc.</para>
<para>At the time of writing, several competing iSCSI target implementations
exist on the Linux platform. Two of them are covered in this white
paper:</para>
<itemizedlist>
<listitem>
<para>
iSCSI Enterprise Target (IET). This was the first production-ready
  iSCSI target implementation for Linux. It uses a split, part-kernel,
  part-userland configuration interface that requires both a specific
  kernel module, and a running management daemon (ietd). The in-kernel
  implementation has not been merged into the mainline Linux kernel
  tree. Still, IET is included and fully supported as part of SUSE
  Linux Enterprise Server (versions 10 and 11), and Debian 5.0
  (<literal>lenny</literal>). Although IET development had quieted down at one time,
  the project is currently quite active and has a small, but very
  productive core development team.
</para>
</listitem>
<listitem>
<para>
Linux SCSI Target Framework (tgt). This aims to be a generic SCSI
  target framework for Linux, of which an iSCSI target is merely an
  implementation (or lower-level driver in tgt terms). The generic
  in-kernel framework that tgt uses is part of mainline Linux since
  release 2.6.20, and has been back-ported to the Red Hat Enterprise
  Linux 5 patched 2.6.18 kernel series. As such, it is fully supported
  on RHEL 5 and CentOS 5 from update 3 onwards; in previous RHEL
  releases it had been available as a technology preview only. tgt is
  also available in RHEL 6 and SLES 11.
</para>
</listitem>
</itemizedlist>
<para>This whitepaper describes a solution to use either of these target
implementations in a highly available iSCSI target configuration.</para>
</sect1>
<sect1 id="_installation">
<title>Installation</title>
  <para></para>
<sect2 id="_installing_scsi_target_framework_on_red_hat_enterprise_linux">
<title>Installing SCSI Target Framework on Red Hat Enterprise Linux</title>
<para>The SCSI Target Framework (tgt) is a fully supported iSCSI
implementation as of Red Hat Enterprise Linux 5 Update 3. To enable
iSCSI target functionality on RHEL, you must install the
<literal>scsi-target-utils</literal> package, using the following command:</para>
<screen>yum install scsi-target-utils</screen>
<para>If, however, you use the older <literal>up2date</literal> package manager instead of
YUM, you must issue the following command instead:</para>
<screen>up2date install scsi-target-utils</screen>
<para>After installation, you should make sure that the tgtd service on
system startup:</para>
<screen>chkconfig tgtd on</screen>
</sect2>
<sect2 id="_installing_an_iscsi_target_implementation_on_suse_linux_enterprise_server">
<title>Installing an iSCSI target implementation on SUSE Linux Enterprise Server</title>
<para>SUSE Linux Enterprise Server 11 comes with two iSCSI target
implementations: iSCSI Enterprise Target (IET) and the SCSI Target
Framework (tgt). You may select either for installation.</para>
<sect3 id="_installing_iet_on_sles_11">
<title>Installing IET on SLES 11</title>
<para>To install IET, issue the following commands:</para>
<screen>zypper install iscsitarget iscsitarget-kmp-&lt;flavor&gt;</screen>
<para>Replace <literal>&lt;flavor&gt;</literal> with your kernel flavor (usually <literal>default</literal>).</para>
<para>Then, make sure that the IET management daemon is started on system startup:</para>
<screen>insserv ietd</screen>
</sect3>
<sect3 id="_installing_tgt_on_sles_11">
<title>Installing tgt on SLES 11</title>
<para>To install tgt, issue the following command:</para>
<screen>zypper install tgt</screen>
<para>tgt requires no additional kernel modules.</para>
<para>Then, to make sure tgt is started automatically on system startup, issue:</para>
<screen>insserv tgtd</screen>
</sect3>
<sect3 id="_installing_iscsi_enterprise_target_on_debian_gnu_linux">
<title>Installing iSCSI Enterprise Target on Debian GNU/Linux</title>
<para>iSCSI Enterprise Target (IET) is available as part of Debian GNU/Linux
5.0 (<literal>lenny</literal>), although the IET kernel modules are not distributed as
part of the Debian stock kernel. Thus, you must install two packages,
one containing the IET administration utilities, and one containing
the kernel modules:</para>
<screen>aptitude install iscsitarget iscsitarget-modules-2.6-&lt;arch&gt;</screen>
<para>Replace <literal>&lt;arch&gt;</literal> with your kernel architecture (usually <literal>amd64</literal>). This
will install the IET module package to match the latest Debian 2.6
kernel for your architecture. If you are using a stock kernel other
than the latest Debian kernel, issue the following command instead:</para>
<screen>aptitude install iscsitarget iscsitarget-modules-`uname -r`</screen>
</sect3>
</sect2>
<sect2 id="_installing_the_pacemaker_cluster_manager_on_red_hat_enterprise_linux">
<title>Installing the Pacemaker cluster manager on Red Hat Enterprise Linux</title>
<para>RHEL 5 packages are provided by the Pacemaker project and are
available the project website. Pacemaker is best installed
using the <literal>yum</literal> package manager. To be able to do so, you must first add
the Pacemaker repository to your repository configuration:</para>
<itemizedlist>
<listitem>
<para>
Download the repository file from
  <ulink url="http://www.clusterlabs.org/rpm/epel-5/clusterlabs.repo">http://www.clusterlabs.org/rpm/epel-5/clusterlabs.repo</ulink> and install
  it into the <literal>/etc/yum.repos.d</literal> directory.
</para>
</listitem>
<listitem>
<para>
Then, install Pacemaker (and dependencies) with <literal>yum install pacemaker.x86_64</literal>.
</para>
</listitem>
</itemizedlist>
</sect2>
<sect2 id="_installing_pacemaker_on_sles_11">
<title>Installing Pacemaker on SLES 11</title>
<para>Installing Pacemaker on SLES 11 requires a valid SUSE Linux Enterprise High Availability Extension
subscription.</para>
<note><para>Enabling SLE 11 HAE is beyond the scope of this manual.</para></note>
<para>Once enabled, you may install Pacemaker with the following command:</para>
<screen>zypper install pacemaker</screen>
<para>Then, to make sure Pacemaker is started automatically on system startup, issue:</para>
<screen>zypper install pacemaker</screen>
</sect2>
</sect1>
<sect1 id="_initial_configuration">
<title>Initial Configuration</title>
<para>This section describes the configuration of a highly available iSCSI
Target and Logical Units (LU) in the context of the Pacemaker cluster
manager.</para>
<sect2 id="_configuring_a_drbd_resource">
<title>Configuring a DRBD resource</title>
<para>First, it is necessary to configure a Pacemaker resource that manages
a DRBD device. This resource will act as the Physical Volume of an LVM
Volume Group to be created later. This example assumes that the LVM
Volume Group is to be called <literal>iscsivg01</literal>, hence, the DRBD resource
uses that same name.</para>
<screen>global {
  usage-count yes;
}

common {
  protocol C;
  disk {
    on-io-error detach;
    fencing resource-only;
  }
  net {
    cram-hmac-alg sha1;
    shared-secret "a6a0680c40bca2439dbe48343ddddcf4";
  }
  syncer {
    rate 30M;
    al-extents 3389;
  }
  handlers {
    fence-peer "/usr/lib/drbd/crm-fence-peer.sh";
    after-resync-target "/usr/lib/drbd/crm-unfence-peer.sh";
    pri-on-incon-degr "echo b &gt; /proc/sysrq-trigger";
  }
}

resource iscsivg01 {
  device /dev/drbd1;
  disk /dev/sda1;
  meta-disk internal;

  on alice {
    address 10.0.42.1:7790;
  }
  on bob {
    address 10.0.42.2:7790;
  }
}</screen>
</sect2>
<sect2 id="_lvm_configuration">
<title>LVM Configuration</title>
<para>It is necessary instruct LVM to read Physical Volume signatures from
DRBD devices, rather than the underlying backing block devices. The
easiest approach for doing this is to mask the underlying block device
from the list of devices LVM scans for PV signatures.</para>
<para>To do so, open the LVM configuration file (<literal>/etc/lvm/lvm.conf</literal>) and edit
the following entries:</para>
<screen>filter = [ "r|/dev/sdb.*|" ]</screen>
<para>In addition, you should disable the LVM cache by setting:</para>
<screen>write_cache_state = 0</screen>
<para>After disabling the LVM cache, make sure you remove any stale cache
entries by deleting <literal>/etc/lvm/cache/.cache</literal>.</para>
<para>You must repeat the above steps on the peer node.</para>
<para>Now, to be able to create an LVM Volume Group, it is first necessary
to initialize the DRBD resource as an LVM Physical Volume. To do so,
after you have initiated the initial synchronization of your DRBD
resource, issue the following commands on the node where your resource
is currently in the Primary role:</para>
<screen>pvcreate /dev/drbd/by-res/iscsivg01</screen>
<para>Now, create an LVM Volume Group that includes this PV:</para>
<screen>vgcreate iscsivg01 /dev/drbd/by-res/iscsivg01</screen>
</sect2>
<sect2 id="_initial_pacemaker_configuration_steps">
<title>Initial Pacemaker configuration steps</title>
<note><para>While this manual covers the configuration of the Pacemaker
cluster manager, the configuration of the cluster stack that Pacemaker
uses is beyond the scope of this manual. Please see
<ulink url="http://clusterlabs.org/wiki/Initial_Configuration">Initial
Configuration</ulink> (from the ClusterLabs Wiki) for details on
bootstrapping a Pacemaker cluster configuration.</para></note>
<para>In a highly available iSCSI target configuration that involves a
2-node cluster, you should</para>
<itemizedlist>
<listitem>
<para>
Disable STONITH;
</para>
</listitem>
<listitem>
<para>
Set Pacemaker&#8217;s no quorum policy to ignore loss of quorum;
</para>
</listitem>
<listitem>
<para>
Set the default resource stickiness to 200.
</para>
</listitem>
</itemizedlist>
<para>To do so, issue the following commands from the CRM shell:</para>
<screen>crm(live)# configure
crm(live)configure# property stonith-enabled="false"
crm(live)configure# property no-quorum-policy="ignore"
crm(live)configure# property default-resource-stickiness="200"
crm(live)configure# commit</screen>
</sect2>
<sect2 id="_creating_an_active_passive_iscsi_configuration">
<title>Creating an Active/Passive iSCSI configuration</title>
<para>An active/passive iSCSI Target consists of the following cluster resources:</para>
<itemizedlist>
<listitem>
<para>
A DRBD resource to replicate data, which is switched from and to the
  Primary and Secondary roles as deemed necessary by the cluster
  resource manager;
</para>
</listitem>
<listitem>
<para>
An LVM Volume Group, which is made available on whichever node
  currently holds the DRBD resource in the Primary role;
</para>
</listitem>
<listitem>
<para>
A virtual, floating cluster IP address, allowing initiators to
  connect to the target no matter which physical node it is running
  on;
</para>
</listitem>
<listitem>
<para>
The iSCSI Target itself;
</para>
</listitem>
<listitem>
<para>
One or more iSCSI Logical Units (LUs), each corresponding to a
  Logical Volume in the LVM Volume Group.
</para>
</listitem>
</itemizedlist>
<para>The following Pacemaker configuration example assumes that
<literal>10.9.9.180</literal> is the virtual IP address to use for a target with the
iSCSI Qualified Name (IQN)
<literal>iqn.2001-04.com.example:storage.example.iscsivg01</literal>.</para>
<para>The target is to contain two Logical Units with LUNs 1 and 2, mapping
to Logical Volumes named <literal>lun1</literal> and <literal>lun2</literal>, respectively.</para>
<para>To start configuring these resources, open the crm shell as <literal>root</literal> (or
any non-<literal>root</literal> user that is part of the <literal>haclient</literal> group), and issue
the following commands:</para>
<screen>crm(live)# configure
crm(live)configure# primitive res_drbd_iscsivg01 \
  ocf:linbit:drbd \
    params drbd_resource="iscsivg01" \
    op monitor interval="10"
crm(live)configure# ms ms_drbd_iscsivg01 res_drbd_iscsivg01 \
  meta master-max="1" master-node-max="1" clone-max="2" \
    clone-node-max="1" notify="true"</screen>
<para>This will create a Master/Slave resource corresponding to the DRBD
resource <literal>iscsivg01</literal>.</para>
<screen>crm(live)configure# primitive res_ip_alicebob01 \
  ocf:heartbeat:IPaddr2 \
    params ip="10.9.9.180" cidr_netmask="24" \
    op monitor interval="10s"
crm(live)configure# primitive res_lvm_iscsivg01 \
  ocf:heartbeat:LVM \
    params volgrpname="iscsivg01" \
    op monitor interval="30s"
crm(live)configure# primitive res_target_iscsivg01 \
  ocf:heartbeat:iSCSITarget \
    params iqn="iqn.2001-04.com.example:storage.example.iscsivg01" \
      tid="1" \
    op monitor interval="10s"</screen>
<note><para>You <emphasis>must</emphasis> specify the numeric target id (<literal>tid</literal>) if you are
using the tgt implementation.  For IET, setting this parameter is
optional.</para></note>
<para>Thus, we have configured a highly available IP address, Volume Group,
and iSCSI Target. We can now add Logical Units:</para>
<screen>crm(live)configure# primitive res_lu_iscsivg01_lun1 \
  ocf:heartbeat:iSCSILogicalUnit \
    params target_iqn="iqn.2001-04.com.example:storage.example.iscsivg01" \
      lun="1" path="/dev/iscsivg01/lun1" \
    op monitor interval="10s"
crm(live)configure# primitive res_lu_iscsivg01_lun2 \
  ocf:heartbeat:iSCSILogicalUnit \
    params target_iqn="iqn.2001-04.com.example:storage.example.iscsivg01" \
      lun="2" path="/dev/iscsivg01/lun2" \
op monitor interval="10s"</screen>
<para>Now to tie all of this together, we must first create a resource group
from the resources associated with our iSCSI Target:</para>
<screen>crm(live)configure# group rg_iscsivg01 \
  res_lvm_iscsivg01 \
  res_target_iscsivg01 res_lu_iscsivg01_lun1 res_lu_iscsivg01_lun2 \
  res_ip_alicebob01</screen>
<para>This group, by Pacemaker default, is <emphasis>ordered</emphasis> and <emphasis>colocated</emphasis>, which
means that the resources contained therein will always run on the same
physical node, will be started in the order as specified, and stopped
in reverse order.</para>
<para>Finally, we have to make sure that this resource group is also started
on the node where DRBD is in the Primary role:</para>
<screen>crm(live)configure# order o_drbd_before_iscsivg01 \
  inf: ms_drbd_iscsivg01:promote rg_iscsivg01:start
crm(live)configure# colocation c_iscsivg01_on_drbd \
  inf: rg_iscsivg01 ms_drbd_iscsivg01:Master</screen>
<para>Now, our configuration is complete, and may be activated:</para>
<screen>crm(live)configure# commit</screen>
</sect2>
<sect2 id="_creating_an_active_active_iscsi_configuration">
<title>Creating an Active/Active iSCSI configuration</title>
<para>An active/active iSCSI Target consists of the following cluster resources:</para>
<para>Two DRBD resources to replicate data, which are switched from and to the Primary and
Secondary roles as deemed necessary by the cluster resource manager;</para>
<itemizedlist>
<listitem>
<para>
Two LVM Volume Groups, which are made available on whichever node
  currently holds the corresponding DRBD resource in the Primary role;
</para>
</listitem>
<listitem>
<para>
Two virtual, floating cluster IP addresses, allowing initiators to
  connect to the target no matter which physical node it is running
  on;
</para>
</listitem>
<listitem>
<para>
The iSCSI Targets themselves;
</para>
</listitem>
<listitem>
<para>
One or more iSCSI Logical Units (LUs), each corresponding to a
  Logical Volume in one of the two LVM Volume Groups
</para>
</listitem>
</itemizedlist>
<para><literal>10.9.9.180</literal> and <literal>10.9.9.181</literal> are the virtual IP addresses to use for
two targets with the iSCSI Qualified Names (IQN)
<literal>iqn.2001-04.com.example:storage.example.iscsivg01</literal> and
<literal>iqn.2001-04.com.example:storage.example.iscsivg02</literal>, respectively.</para>
<para>The targets are to contain two Logical Units with LUNs 1 and 2,
mapping to Logical Volumes named <literal>lun1</literal> and <literal>lun2</literal> in each Volume
Group, respectively.</para>
<para>To start configuring these resources, open the <literal>crm</literal> shell as <literal>root</literal>
(or any non-<literal>root</literal> user that is part of the <literal>haclient</literal> group), and
issue the following commands:</para>
<screen>crm(live)# configure
crm(live)configure# primitive res_drbd_iscsivg01 \
  ocf:linbit:drbd \
    params drbd_resource="iscsivg01" \
    op monitor interval="10s"
crm(live)configure# ms ms_drbd_iscsivg01 res_drbd_iscsivg01 \
  meta master-max="1" master-node-max="1" clone-max="2" \
    clone-node-max="1" notify="true"
crm(live)configure# primitive res_drbd_iscsivg02 \
  ocf:linbit:drbd \
    params drbd_resource="iscsivg02" \
  op monitor interval="10s"
crm(live)configure# ms ms_drbd_iscsivg01 res_drbd_iscsivg02 \
  meta clone-max="2" notify="true"</screen>
<para>This will create Master/Slave resources corresponding to the DRBD
resources <literal>iscsivg01</literal> and <literal>iscsivg02</literal>.</para>
<screen>crm(live)configure# primitive res_ip_alicebob01 \
  ocf:heartbeat:IPaddr2 \
    params ip="10.9.9.180" cidr_netmask="24" \
    op monitor interval="10s"
crm(live)configure# primitive res_ip_alicebob02 \
  ocf:heartbeat:IPaddr2 \
    params ip="10.9.9.181" cidr_netmask="24" \
    op monitor interval="10s"
crm(live)configure# primitive res_lvm_iscsivg01 \
  ocf:heartbeat:LVM \
    params volgrpname="iscsivg01" \
    op monitor interval="30s"
crm(live)configure# primitive res_lvm_iscsivg01 \
  ocf:heartbeat:LVM \
    params volgrpname="iscsivg02" \
    op monitor interval="30s"
crm(live)configure# primitive res_target_iscsivg01 \
  ocf:heartbeat:iSCSITarget \
    params iqn="iqn.2001-04.com.example:storage.example.iscsivg01" \
      tid="1" \
    op monitor interval="10s"
crm(live)configure# primitive res_target_iscsivg02 \
  ocf:heartbeat:iSCSITarget \
    params iqn="iqn.2001-04.com.example:storage.example.iscsivg02" \
      tid="2" \
    op monitor interval="10s</screen>
<note><para>You <emphasis>must</emphasis> specify the numeric target id (<literal>tid</literal>) if you are
using the tgt implementation. For IET, setting this parameter is
optional.</para></note>
<para>Thus, we have configured a highly available IP address, Volume Group,
and iSCSI Target. We can now add Logical Units:</para>
<screen>crm(live)configure# primitive res_lu_iscsivg01_lun1 \
  ocf:heartbeat:iSCSILogicalUnit \
    params target_iqn="iqn.2001-04.com.example:storage.example.iscsivg01" \
      lun="1" path="/dev/iscsivg01/lun1" \
    op monitor interval="10s"
crm(live)configure# primitive res_lu_iscsivg01_lun2 \
  ocf:heartbeat:iSCSILogicalUnit \
    params target_iqn="iqn.2001-04.com.example:storage.example.iscsivg01" \
      lun="2" path="/dev/iscsivg0
crm(live)configure# primitive res_lu_iscsivg02_lun1 \
  ocf:heartbeat:iSCSILogicalUnit \
    params target_iqn="iqn.2001-04.com.example:storage.example.iscsivg02" \
      lun="1" path="/dev/iscsivg02/lun1" \
    op monitor interval="10s"
crm(live)configure# primitive res_lu_iscsivg02_lun2 \
  ocf:heartbeat:iSCSILogicalUnit \
    params target_iqn="iqn.2001-04.com.example:storage.example.iscsivg02" \
      lun="2" path="/dev/iscsivg02/lun2" \
    op monitor interval="10s"</screen>
<para>Now to tie all of this together, we must first create resource groups
from the resources associated with our iSCSI Targets:</para>
<screen>crm(live)configure# group rg_iscsivg01 \
  res_lvm_iscsivg01 \
  res_target_iscsivg01 res_lu_iscsivg01_lun1 res_lu_iscsivg01_lun2 \
  res_ip_alicebob01
crm(live)configure# group rg_iscsivg02 \
  res_lvm_iscsivg02 \
  res_target_iscsivg02 res_lu_iscsivg02_lun1 res_lu_iscsivg02_lun2 \
  res_ip_alicebob02</screen>
<para>These groups, by Pacemaker default, are <emphasis>ordered</emphasis> and <emphasis>colocated</emphasis>,
which means that the resources contained therein will always run on
the same physical node, will be started in the order as specified, and
stopped in reverse order.</para>
<para>We now have to make sure that this resource group is also started on
the node where DRBD is in the Primary role:</para>
<screen>crm(live)configure# order o_drbd_before_iscsivg01 \
  inf: ms_drbd_iscsivg01:promote rg_iscsivg01:start
crm(live)configure# colocation c_iscsivg01_on_drbd \
  inf: rg_iscsivg01 ms_drbd_iscsivg01:Master
crm(live)configure# order o_drbd_before_iscsivg02 \
  inf: ms_drbd_iscsivg02:promote rg_iscsivg02:start
crm(live)configure# colocation c_iscsivg01_on_drbd \
  inf: rg_iscsivg01 ms_drbd_iscsivg01:Master
crm(live)configure# colocation c_iscsivg02_on_drbd \
  inf: rg_iscsivg02 ms_drbd_iscsivg02:Master</screen>
<para>Now, our configuration is complete, and may be activated:</para>
<screen>crm(live)configure# commit</screen>
</sect2>
</sect1>
<sect1 id="_security_considerations">
<title>Security Considerations</title>
<para>Access to iSCSI targets may be restricted in one of several fashions:</para>
<itemizedlist>
<listitem>
<para>
By initiator address.  Access to iSCSI targets may be restricted to
  specific initiators, identified by their IP addresses or iSCSI
  Qualified Name (IQN).
</para>
</listitem>
<listitem>
<para>
By initiator credentials. iSCSI Targets may be protected with a
  username and password.  Initiators are then forced to login with
  those credentials using the Challenge-Response Authentication
  Protocol (CHAP). This protocol does not transmit passwords in the
  clear, instead it uses password hashes in a challenge-reponse
  exchange.
</para>
</listitem>
<listitem>
<para>
Combined approach. The two above approaches may be combined, such
  that targets can be connected to only from specific initiator IP
  addresses, where the initiators have to additionally pass CHAP
  authentication.
</para>
</listitem>
</itemizedlist>
<sect2 id="_restricting_target_access_by_initiator_address">
<title>Restricting target access by initiator address</title>
<para>To restrict access to a target to one or more initiator addresses, use
the <literal>initiators</literal> parameter supported by the iSCSI Target Pacemaker
resource agent:</para>
<screen>crm(live)configure# edit res_target_iscsivg01</screen>
<para>This will bring up a text editor containing the current configuration
parameters for this resource. Edit the resource to include the
allowed_initiators parameter, containing a space- separated list of
initiator IP addresses allowed to connect to this target. In the
example below, access is granted to initiator IP addresses <literal>10.9.9.60</literal>
and <literal>10.9.9.170</literal>.</para>
<note><para>This approach is valid when using iSCSI Enterprise Target (IET)
or SCSI Target Framework (tgt) as the underlying iSCSI target
implementation.</para></note>
<screen>primitive res_target_iscsivg01 \
  ocf:heartbeat:iSCSITarget \
    params iqn="iqn.2001-04.com.example:storage.example.iscsivg01" \
      allowed_initiators="10.9.9.60 10.9.9.170" \
    op monitor interval="10s"</screen>
<para>When you close the editor, the configuration changes are inserted into
the CIB configuration. To commit these changes, as usual, enter the
following command:</para>
<screen>crm(live)configure# commit</screen>
<para>After you commit the changes, the target will immediately reconfigure
and enable the access restrictions.</para>
<warning><para>If initiators are connected to the target at the time of
re-configuration, and one of the connected initiators is not included
in the <literal>initiators</literal> list for this resource, then those initiators will
lose access to the target, possibly resulting in disruption on the
initiator node. Use with care.</para></warning>
</sect2>
<sect2 id="_restricting_target_access_by_using_chap_credentials">
<title>Restricting target access by using CHAP credentials</title>
<para>To create a username and password which initiators must use to log in
to an iSCSI target, use the <literal>username</literal> and <literal>password</literal> parameters
supported by the iSCSITarget Pacemaker resource agent:</para>
<screen>crm(live)configure# edit res_target_iscsivg01</screen>
<para>This will bring up a text editor containing the current configuration
parameters for this resource.  Edit the resource to include the
<literal>username</literal> and <literal>password</literal> parameters, containing the username and
password to access the target. In the example below, access is granted
to initiators using a username of <literal>iscsi</literal> and password of
<literal>zi1caighaiTo</literal>.</para>
<screen>primitive res_target_iscsivg01 \
  ocf:heartbeat:iSCSITarget \
    params iqn="iqn.2001-04.com.example:storage.example.iscsivg01" \
      incoming_username="iscsi" \
      incoming_password="zi1caighaiTo" \
    op monitor interval="10s"</screen>
<note><para>Some iSCSI initiator implementations require that the CHAP
password is at least 12 bytes long.</para></note>
<para>When you close the editor, the configuration changes are inserted into
the CIB configuration. To commit these changes, as usual, enter the
following command:</para>
<screen>crm(live)configure# commit</screen>
<para>After you commit the changes, the target will immediately reconfigure
and enable the access restrictions.</para>
  
<warning><para>If initiators are connected to the target at the time of
target re-configuration, they will invariably lose target access until
re-configured with matching credentials themselves. As this is likely
to cause disruption on the initiator node, you should change usernames
and/or passwords only on targets with no initiator activity.</para></warning>
</sect2>
</sect1>
<sect1 id="_setting_configuration_parameters">
<title>Setting configuration parameters</title>
<para>This section outlines some of the configuration parameters one may
want to set in a highly available iSCSI Target configuration.</para>
<sect2 id="_per_target_configuration_parameters">
<title>Per-target configuration parameters</title>
<para>You may set configuration parameters at the iSCSI target level by
using the <literal>additional_parameters</literal> instance attribute defined for the
iSCSITarget resource agent.</para>
<para>To set, for example, the <literal>DefaultTime2Retain</literal> and <literal>DefaultTime2Wait</literal>
session parameters to 60 and 5 seconds, respectively, modify your
target resource as follows:</para>
<screen>crm(live)configure# edit res_target_iscsivg01</screen>
<screen>primitive res_target_iscsivg01 \
  ocf:heartbeat:iSCSITarget \
    params iqn="iqn.2001-04.com.example:storage.example.iscsivg01" \
      additional_parameters="DefaultTime2Retain=60 DefaultTime2Wait=5"
    op monitor interval="10s"</screen>
<screen>crm(live)configure# commit</screen>
</sect2>
<sect2 id="_per_lu_configuration_parameters">
<title>Per-LU configuration parameters</title>
  <para></para>
<sect3 id="_scsi_id_and_serial_number">
<title>SCSI ID and serial number</title>
<para>For some applications, smooth uninterrupted failover requires that the
SCSI ID associated with a Logical Unit is identical regardless of
which node currently exports the LU. The same applies to the SCSI
Serial Number. Examples of such applications are the device-mapper
multipath target (<literal>dm-multipath</literal>) on Linux, and the Microsoft iSCSI
initiator on Windows.</para>
<para>The <literal>iSCSILogicalUnit</literal> resource agent attempts to select sensible,
consistent values for these fields as appropriate for the underlying
iSCSI implementation. Still, you may prefer to set the SCSI ID and/or
serial number explicitly as part of the LU configuration.</para>
<para>To set a SCSI ID or serial number for an exported LU, edit the
<literal>iSCSILogicalUnit</literal> resource to include the <literal>scsi_id</literal> or <literal>scsi_sn</literal>
parameter (or both):</para>
<screen>crm(live)configure# edit res_lu_lun1</screen>
<screen>primitive res_lu_lun1 \
  ocf:heartbeat:iSCSILogicalUnit \
    params
    target_iqn="iqn.2001-04.com.example:storage.example.iscsivg01"
      lun="1" path="/dev/iscsivg01/lun1" \
      scsi_id="iscsivg01.lun1" scsi_sn="4711" \
    op monitor interval="10s"</screen>
<screen>crm(live)configure# commit</screen>
</sect3>
<sect3 id="_vendor_id_and_product_id">
<title>Vendor ID and Product ID</title>
<para>Two other SCSI Vital Product Data (VPD) fields that you may wish to
set explicitly are the SCSI Vendor ID and Product ID fields. To do so,
add the resource parameters <literal>vendor_id</literal> and/or <literal>product_id</literal> to your LU
configuration:</para>
<screen>crm(live)configure# edit res_lu_lun1</screen>
<screen>primitive res_lu_lun1 \
  ocf:heartbeat:iSCSILogicalUnit \
    params target_iqn="iqn.2001-04.com.example:storage.example.iscsivg01" \
      lun="1" path="/dev/iscsivg01/lun1" \
      vendor_id="STGT" scsi_id="iscsivg01.lun1" scsi_sn="4711" \
    op monitor interval="10s"</screen>
<screen>crm(live)configure# commit</screen>
<note><para>Interestingly, STGT uses a default vendor ID of IET. If you are
using the tgt target implementation, you may want to set the vendor ID
to a non-default value as shown in the example, to avoid confusion.</para></note>
</sect3>
</sect2>
</sect1>
<sect1 id="_using_highly_available_iscsi_targets">
<title>Using highly available iSCSI Targets</title>
<para>This section describes some common usage scenarios for highly
available iSCSI Targets.</para>
<sect2 id="_connecting_to_iscsi_targets_from_linux">
<title>Connecting to iSCSI targets from Linux</title>
<para>The recommended way of connecting to a highly available iSCSI Target
from Linux is to use the initiator delivered by the Open iSCSI project
(<ulink url="http://www.open-iscsi.org">http://www.open-iscsi.org</ulink>).</para>
<para>After installing the Open iSCSI administration utilities, it is first
necessary to start the iSCSI initiatior daemon, <literal>iscsid</literal>. To do so,
issue one of the following commands (depending on your distribution):</para>
<screen>/etc/init.d/open-iscsi start
rcopen-iscsi start
service open-iscsi start</screen>
<para>Now you may start a discovery session on your target portal. Assuming
your cluster IP address for the target is 10.9.9.180, you may do so
using the following command:</para>
<screen>iscsiadm -m discovery -p 10.9.9.180 -t sendtargets</screen>
<para>The output from this command should include the names of all targets
you have configured.</para>
<screen>10.9.9.180:3260,1 iqn.2001-04.com.example:storage.example.iscsivg01</screen>
<note><para>If a configured target does not appear in this list, check
whether your initiator has been blocked from accessing this target via
an initiator restriction (see
<xref linkend="_restricting_target_access_by_initiator_address"/>).</para></note>
<para>Then, if you have configured your iSCSI Target to require
authentication (see
<xref linkend="_restricting_target_access_by_using_chap_credentials"/>), you must
set a username and password for any target you wish to connect to. To
do so, issue the following commands:</para>
<screen>iscsiadm -m node -p 10.9.9.180 \
  -T iqn.2001-04.com.example:storage.example.iscsivg01 \
  --op update \
  -n node.session.auth.authmethod -v CHAP
iscsiadm -m node -p 10.9.9.180 \
  -T iqn.2001-04.com.example:storage.example.iscsivg01 \
  --op update \
  -n node.session.auth.username -v iscsi
iscsiadm -m node -p 10.9.9.180 \
  -T iqn.2001-04.com.example:storage.example.iscsivg01 \
  --op update \
  -n node.session.auth.password -v zi1caighaiTo</screen>
<para>Finally, you may log in to the target, which will make all LUs
configured therein available as local SCSI devices:</para>
<screen>iscsiadm -m node -p 10.9.9.180 \
  -T iqn.2001-04.com.example:storage.example.iscsivg01 \
  --login</screen>
</sect2>
<sect2 id="_connecting_to_iscsi_targets_from_microsoft_windows">
<title>Connecting to iSCSI targets from Microsoft Windows</title>
<para>On Microsoft Windows, iSCSI Target connections are managed by the
Microsoft iSCSI Initiator Service, which is available free of charge
from Microsoft and my be installed on Microsoft Windows Server 2003
and 2008.</para>
<important><para>Smooth, uninterrupted target failover in conjunction with
the Microsoft iSCSI Initiator is guaranteed only if the Logical Units'
SCSI IDs and serial numbers are persistent across the failover
process. Refer to the <xref linkend="_scsi_id_and_serial_number"/> for
considerations on consistent SCSI IDs and SNs.</para></important>
<sect3 id="_configuring_microsoft_iscsi_initiator_using_the_control_panel_applet">
<title>Configuring Microsoft iSCSI Initiator using the Control Panel applet</title>
<para>To configure access to an iSCSI target from Microsoft Windows, open
the Control Panel item <literal>Microsoft iSCSI Initiator</literal>. First, click on
the <literal>Discovery</literal> tab, then under <literal>Target Portals</literal> click <literal>Add</literal> to add a
connection to a target portal.</para>
<para>In the <literal>IP address or DNS name</literal> field, enter the floating cluster IP
address of your configured iSCSI target as the target IP address. You
may of course also use a host name if it resolves to the cluster IP
address.</para>
<figure><title>Configuring target IP address on Windows</title>
  <mediaobject>
  <imageobject>
  <imagedata fileref="screenshot-windows-add-portal.png" width="50%"   />
  </imageobject>
 <!-- <textobject><phrase>screenshot-windows-add-portal.png</phrase></textobject>-->
</mediaobject>
</figure>
<para>If your target is protected by CHAP authentication, click
<literal>Advanced&#8230;</literal> to open the advanced settings dialog. Check the <literal>CHAP
logon information</literal> checkbox. Enter the username and password
configured for target authentication.</para>
<figure><title>Configuring CHAP authentication on Windows</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="screenshot-windows-chap-auth.png" width="50%"   />
  </imageobject>
  <!--<textobject><phrase>screenshot-windows-chap-auth.png</phrase></textobject>-->
</mediaobject>
</figure>
<note><para>Be sure to leave the <literal>Perform mutual authentication</literal> checkbox
unchecked.</para></note>
<para>Next, select the Targets tab. It should now list any targets visible
to the initiatior under the configured portal address. In the example
below, there is one target available. Since the target has not been
logged into, its status is listed as <literal>Inactive</literal>:</para>
<figure><title>Discovered iSCSI target on Windows</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="screenshot-windows-discovered-target.png" width="50%"   />
  </imageobject>
  <!--<textobject><phrase>screenshot-windows-discovered-target.png</phrase></textobject>-->
</mediaobject>
</figure>
<para>You may now click <literal>Log On&#8230;</literal> to log on to the target:</para>
<figure><title>iSCSI target logon dialog on Windows</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="screenshot-windows-logon-target.png" width="50%"   />
  </imageobject>
  <!--<textobject><phrase>screenshot-windows-logon-target.png</phrase></textobject>-->
</mediaobject>
</figure>
<para>Be sure to check box the labeled <literal>Automatically restore this
connection when the system boots</literal>, to ensure that the connection to
the configured target portal is automatically restored on system boot.</para>
<para>When you have configured your initiator correctly, the target should
be listed as <literal>Connected</literal> in the Targets list:</para>
<figure><title>Connected target on Windows</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="screenshot-windows-connected-target.png" width="50%"   />
  </imageobject>
  <!--<textobject><phrase>screenshot-windows-connected-target.png</phrase></textobject>-->
</mediaobject>
</figure>
</sect3>
<sect3 id="_configuring_microsoft_iscsi_initiator_using_literal_iscsicli_literal">
<title>Configuring Microsoft iSCSI Initiator using <literal>iscsicli</literal></title>
<para>Microsoft iSCSI Initiator comes with a command line utility named
<literal>iscsicli</literal>, which may also be used to configure access to iSCSI
portals and targets.</para>
<para>To connect to a target portal, use the following command:</para>
<screen>C:\&gt;iscsicli QAddTargetPortal 10.9.9.180
Microsoft iSCSI Initiator version 2.0 Build 3825

The operation completed successfully.</screen>
<para>You should now be able to retrieve information associated with the
newly added target:</para>
<screen>C:\&gt;iscsicli ListTargetPortals
Microsoft iSCSI Initiator version 2.0 Build 3825

Total of 1 portals are persisted:

    Address and Socket   : 10.9.9.180 3260
    Symbolic Name        :
    Initiator Name       :
    Port Number          : &lt;Any Port&gt;
    Security Flags       : 0x0
    Version              : 0
    Information Specified: 0x0
    Login Flags          : 0x0

The operation completed successfully.</screen>
<para>Next, list the targets accessible via this target portal:</para>
<screen>C:\&gt;iscsicli ListTargets
Microsoft iSCSI Initiator version 2.0 Build 3825

Targets List:
    iqn.2001-04.com.linbit:storage.alicebob.iscsivg01
The operation completed successfully.</screen>
<para>You may now add the newly discovered target to your configuration, as
a persistent target.  <literal>iscsicli</literal> requires that you enter the same
parameters both for target login, and for making the target
persistent:</para>
<screen>C:\&gt;iscsicli
PersistentLoginTarget iqn.2001-04.com.linbit:storage.alicebob.iscsivg01
T * * * * * * * * * * * * * * * 0
Microsoft iSCSI Initiator version 2.0 Build 3825

LoginTarget to iqn.2001-04.com.linbit:storage.alicebob.iscsivg01
on &lt;no init instance&gt; to &lt;no portal&gt;/0
The operation completed successfully.</screen>
<screen>C:\&gt;iscsicli
LoginTarget iqn.2001-04.com.linbit:storage.alicebob.iscsivg01
T * * * * * * * * * * * * * * * 0
Microsoft iSCSI Initiator version 2.0 Build 3825
LoginTarget to iqn.2001-04.com.linbit:storage.alicebob.iscsivg01 on
&lt;no init instance&gt; to &lt;no portal&gt;/0
Session Id is 0xfffffadfe5f70018-0x4000013700000010
Connection Id is 0xfffffadfe5f70018-0xf
The operation completed successfully.</screen>
<note><para>If your target is configured with CHAP authentication, replace
the trailing <literal>* * 0</literal> with <literal>&lt;username&gt; &lt;password&gt; 1</literal>.</para></note>
<para>Finally, import Logical Units into your local disk configuration:</para>
<screen>C:\&gt;iscsicli bindpersistentvolumes
Microsoft iSCSI Initiator version 2.0 Build 3825

The operation completed successfully.</screen>
</sect3>
<sect3 id="_initializing_iscsi_disks_on_windows">
<title>Initializing iSCSI disks on Windows</title>
<note><para>When you connect a Windows host to a target that uses tgt for
the first time, the Windows Plug and Play manager displays a new,
unknown storage controller device.  This is the virtual “controller”
LUN 0 that tgt exposes. No driver for this device exists, nor is one
necessary. Simply click through the New Device Wizard and choose not
to install any driver. This consideration does not apply if your iSCSI
target cluster uses an implementation other than tgt.</para></note>
<para>After you have added a target&#8217;s Logical Units to your computer&#8217;s
configuration as local disks, open the <literal>Computer Management</literal> console
from the Administrative Tools menu and select <literal>Logical Disk
Manager</literal>. Your new disk should now be listed among the local drives
available:</para>
<figure><title>New iSCSI disks in Windows Logical Disk Manager</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="screenshot-windows-diskman-uninitialized.png" width="50%"   />
  </imageobject>
  <!--<textobject><phrase>screenshot-windows-diskman-uninitialized.png</phrase></textobject>-->
</mediaobject>
</figure>
<para>Right-click on one of the new disks labeled <literal>Unknown</literal> and <literal>Not
Initialized</literal>, and select <literal>Initialize Disk</literal>. You will be prompted to
select one or more disks to initialize:</para>
<figure><title>Initializing iSCSI disks in Windows</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="screenshot-windows-diskman-initialize.png" width="50%"/>
  </imageobject>
  <!--<textobject><phrase>screenshot-windows-diskman-initialize.png</phrase></textobject>-->
</mediaobject>
</figure>
<para>After drives are initialized, their status changes to <literal>Basic</literal> and
<literal>Online</literal>. You may now format the drive, assign a drive letter, or
mount point, just as you would with a local disk.</para>
<figure><title>iSCSI disks in Windows after initialization</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="screenshot-windows-diskman-initialized.png" width="50%" />
  </imageobject>
<!--  <textobject><phrase>screenshot-windows-diskman-initialized.png</phrase></textobject>-->
</mediaobject>
</figure>
<warning><para>Do not convert the iSCSI disk to a Dynamic Disk. This is not
supported on Windows; iSCSI connected drives should always remain
configured as Basic Disks.</para></warning>
</sect3>
</sect2>
</sect1>
<sect1 id="_feedback">
<title>Feedback</title>
<para>Any questions or comments about this document are highly appreciated
and much encouraged.  Please contact the author(s) directly; contact
email addresses are listed on the title page.</para>
<para>For a public discussion about the concepts mentioned in this white
paper, you are invited to subscribe and post to the drbd-user mailing
list. Please see <ulink url="http://lists.linbit.com/listinfo/">http://lists.linbit.com/listinfo/</ulink> drbd-user for
details.</para>
</sect1>
</article>
