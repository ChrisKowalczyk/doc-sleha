<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE appendix PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd" [
 <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
 <!ENTITY % entities SYSTEM "entity-decl.ent">
 %entities;
]>
<appendix id="cha.ha.changes">
 <title>What's New?</title>
 <para>
  The most important software modifications from version to version are
  outlined in the following sections. This summary indicates, for example,
  whether basic settings have been completely reconfigured, configuration
  files have been moved to other places, or other significant changes
  happened.
 </para>
 <para>For more details and the most recent information, refer to the release
  notes of the respective product version. They are available in the installed system at
  <filename>/usr/share/doc/release-notes</filename>.
 </para>
 <sect1 id="sec.ha.changes.sle11">
  <title>Version 10 SP3 to Version 11</title>

  <para>
   With &sls; 11, the cluster stack has changed from &hb; to &ais;. &ais;
   implements an industry standard API, the Application Interface
   Specification (AIS), published by the Service Availability Forum. The
   cluster resource manager from &sls; 10 has been retained but has been
   significantly enhanced, ported to &ais; and is now known as Pacemaker.
  </para>

  <para>
   For more details what changed in the &ha; components from &slsreg; 10 SP3
   to &sls; 11, refer to the following sections.
  </para>

  <sect2 id="sec.ha.changes.sle11.new">
   <title>New Features and Functions Added</title>
   <variablelist>
    <varlistentry id="vle.ha.news.fail">
     <term>Migration Threshold and Failure Timeouts</term>
     <listitem>
      <para>
       The &hasi; now comes with the concept of a migration threshold and
       failure timeout. You can define a number of failures for resources,
       after which they will migrate to a new node. By default, the node
       will no longer be allowed to run the failed resource until the
       administrator manually resets the resource’s failcount. However it
       is also possible to expire them by setting the resource’s
       <literal>failure-timeout</literal> option.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry id="vle.ha.news.defaults">
     <term>Resource and Operation Defaults</term>
     <listitem>
      <para>
       You can now set global defaults for resource options and operations.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Support for Offline Configuration Changes</term>
     <listitem>
      <para>
       Often it is desirable to preview the effects of a series of changes
       before updating the configuration atomically. You can now create a
       <quote>shadow</quote> copy of the configuration that can be edited
       with the command line interface, before committing it and thus
       changing the active cluster configuration atomically.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Reusing Rules, Options and Sets of Operations</term>
     <listitem>
      <para>
       Rules, instance_attributes, meta_attributes and sets of operations
       can be defined once and referenced in multiple places.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Using XPath Expressions for Certain Operations in the CIB</term>
     <listitem>
      <para>
       The CIB now accepts XPath-based <literal>create</literal>,
       <literal>modify</literal>, <literal>delete</literal> operations. For
       more information, refer to the <command>cibadmin</command> help text.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Multi-dimensional Collocation and Ordering Constraints</term>
     <listitem>
      <para>
       For creating a set of collocated resources, previously you could
       either deﬁne a resource group (which could not always accurately
       express the design) or you could deﬁne each relationship as an
       individual constraint&mdash;causing a constraint explosion as the
       number of resources and combinations grew. Now you can also use an
       alternate form of collocation constraints by defining
       <literal>resource_sets</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Connection to the CIB From Non-cluster Machines</term>
     <listitem>
      <para>
       Provided Pacemaker is installed on a machine, it is possible to
       connect to the cluster even if the machine itself is not a part of
       it.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Triggering Recurring Actions at Known Times</term>
     <listitem>
      <para>
       By default, recurring actions are scheduled relative to when the
       resource started, but this is not always desirable. To specify a
       date/time that the operation should be relative to, set the
       operation’s interval-origin. The cluster uses this point to
       calculate the correct start-delay such that the operation will occur
       at origin + (interval * N).
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 id="sec.ha.changes.sle11.changed">
   <title>Changed Features and Functions</title>
   <variablelist>
    <varlistentry id="vle.ha.news.options">
     <term>Naming Conventions for Resource and Custer Options</term>
     <listitem>
      <para>
       All resource and cluster options now use dashes (-) instead of
       underscores (_). For example, the <literal>master_max</literal> meta
       option has been renamed to <literal>master-max</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Renaming of <literal>master_slave</literal> Resource </term>
     <listitem>
      <para>
       The <literal>master_slave</literal> resource has been renamed to
       <literal>master</literal>. Master resources are a special type of
       clone that can operate in one of two modes.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Container Tag for Attributes</term>
     <listitem>
      <para>
       The <literal>attributes</literal> container tag has been removed.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Operation Field for Prerequisites</term>
     <listitem>
      <para>
       The <literal>pre-req</literal> operation field has been renamed
       <literal>requires</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Interval for Operations</term>
     <listitem>
      <para>
       All operations must have an interval. For start/stop actions the
       interval must be set to <literal>0</literal> (zero).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Attributes for Collocation and Ordering Constraints</term>
     <listitem>
      <para>
       The attributes of collocation and ordering constraints were renamed
       for clarity.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Cluster Options for Migration Due to Failure</term>
     <listitem>
      <para>
       The <literal>resource-failure-stickiness</literal> cluster option has
       been replaced by the <literal>migration-threshold</literal> cluster
       option. See also <xref linkend="vle.ha.news.fail"/>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Arguments for Command Line Tools</term>
     <listitem>
      <para>
       The arguments for command-line tools have been made consistent. See
       also <xref linkend="vle.ha.news.options"/>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Validating and Parsing XML</term>
     <listitem>
      <para>
       The cluster configuration is written in XML. Instead of a Document
       Type Definition (DTD), now a more powerful RELAX&nbsp;NG schema is
       used to define the pattern for the structure and content.
       <literal>libxml2</literal> is used as parser.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><literal>id</literal> Fields</term>
     <listitem>
      <para>
       <literal>id</literal> fields are now XML IDs which have the following
       limitations:
      </para>
      <itemizedlist>
       <listitem>
        <para>
         IDs cannot contain colons.
        </para>
       </listitem>
       <listitem>
        <para>
         IDs cannot begin with a number.
        </para>
       </listitem>
       <listitem>
        <para>
         IDs must be globally unique (not just unique for that tag).
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>References to Other Objects</term>
     <listitem>
      <para>
       Some fields (such as those in constraints that refer to resources)
       are IDREFs. This means that they must reference existing resources or
       objects in order for the configuration to be valid. Removing an
       object which is referenced elsewhere will therefore fail.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 id="sec.ha.changes.sle11.removed">
   <title>Removed Features and Functions</title>
   <variablelist>
    <varlistentry>
     <term>Setting Resource Meta Options</term>
     <listitem>
      <para>
       It is no longer possible to set resource meta-options as top-level
       attributes. Use meta attributes instead. See also the
       <command>crm_resource</command> man page.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Setting Global Defaults</term>
     <listitem>
      <para>
       Resource and operation defaults are no longer read from
       <literal>crm_conﬁg</literal>.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
 </sect1>
 <sect1 id="sec.ha.changes.sle11.sp1">
  <title>Version 11 to Version 11 SP1</title>

  <variablelist>
   <varlistentry>
    <term>Cluster Configuration File</term>
    <listitem>
     <para>
      The main cluster configuration file has changed from
      <filename>/etc/ais/openais.conf</filename> to
      <filename>/etc/corosync/corosync.conf</filename>. Both files are very
      similar. When upgrading from &sle; &hasi; 11 to SP1, a script takes
      care of the minor differences between those files. For more
      information about the relationship between &ais; and &corosync;, see
      <ulink url="http://www.corosync.org/doku.php?id=faq:why">.</ulink>
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Rolling Upgrade</term>
    <listitem>
     <para>
      In order to migrate existing clusters with minimal downtime,
      &productname; allows you to perform a <quote>rolling upgrade</quote>
      from &productname; 11 to 11 SP1. The cluster is still online while you
      upgrade one node after the other.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Automatic Cluster Deployment</term>
    <listitem>
     <para>
      For easier cluster deployment, &ay; allows you to clone existing
      nodes. &ay; is a system for installing one or more &sle; systems
      automatically and without user intervention, using an &ay; profile
      that contains installation and configuration data. The profile tells
      &ay; what to install and how to configure the installed system to get
      a completely ready-to-use system in the end. This profile can be used
      for mass deployment in different ways.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Transfer of Configuration Files </term>
    <listitem>
     <para>
      &productname; ships with &csync;, a tool for replication of
      configuration files across all nodes in the cluster. It can handle any
      number of hosts and it is also possible to synchronize files among
      certain subgroups of hosts only. Use &yast; to configure the hostnames
      and the files that should be synchronized with &csync;.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Web-Interface for Cluster Management</term>
    <listitem>
     <para>
      The &hasi; now also includes the &haweb; (&hawk;), a Web-based user
      interface for management tasks. It allows you to monitor and
      administer your Linux cluster also from non-Linux machines. It is also
      an ideal solution in case your system does not provide or allow a
      graphical user interface.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Templates for Resource Configuration </term>
    <listitem>
     <para>
      When using the command line interface to create and configure
      resources, you can now choose from various resource templates for
      quicker and easier configuration.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Load-based Placement of Resources</term>
    <listitem>
     <para>
      By defining the capacity a certain node <emphasis>provides</emphasis>,
      the capacity a certain resource <emphasis>requires</emphasis> and by
      choosing one of several placement strategies in the cluster, resources
      can be placed according to their load impact to prevent decrease of
      cluster performance.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Cluster-aware Active/Active RAID1</term>
    <listitem>
     <para>
      It is now possible to create disaster-resilient storage configurations
      from two independent SANs, using
      <systemitem class="daemon"
       >cmirrord</systemitem>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Read-only GFS2 Support</term>
    <listitem>
     <para>
      For easier migration from GFS2 to OCFS2, you can mount your GFS2 file
      systems in read-only mode to copy the data to an OCFS2 file system.
      OCFS2 is fully supported by &productname;.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>SCTP Support for OCFS2 </term>
    <listitem>
     <para>
      If redundant rings are configured, OCFS2 and DLM can automatically use
      redundant communication paths via SCTP, independent of network device
      bonding.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Storage Protection</term>
    <listitem>
     <para>
      For additional layers of security in protecting your storage from data
      corruption, you can use a combination of IO fencing (with the
      <literal>external/sbd</literal> fencing device) and the
      <systemitem
       class="resource">sfex</systemitem> resource agent
      to ensure exclusive storage access.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Samba Clustering</term>
    <listitem>
     <para>
      The &hasi; now supports CTDB, the cluster implementation of the
      trivial database. This allows you configure a clustered Samba
      server&mdash;providing an &ha; solution also for heterogeneous
      environments.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>&yast; Module for IP Load Balancing</term>
    <listitem>
     <para>
      The new module allows configuration of kernel-based load balancing
      with a graphical user interface. It is a front-end for
      <systemitem
       class="daemon">ldirectord</systemitem>, a
      user-space daemon for managing &lvs; and monitoring the real servers.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 id="sec.ha.changes.sle11.sp2">
  <title>Version 11 SP1 to Version 11 SP2</title>

  <variablelist>
   <varlistentry>
    <term><xref linkend="cha.ha.geo" xrefstyle="select:title"/>
    </term>
    <listitem>
     <para>
      Apart from local clusters and metro area clusters, &productnamereg;
      &productnumber; also supports multi-site clusters. That means you can
      have multiple, geographically dispersed sites with a local cluster
      each. Failover between these clusters is coordinated by a higher level
      entity, the so-called <literal>booth</literal>. Support for multi-site
      clusters is available as a separate option to &productname;.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><xref linkend="cha.ha.acl" xrefstyle="select:title"/>
    </term>
    <listitem>
     <para>
      For defining fine-grained access rights to any part of the cluster
      configuration ACLs are supported. If this feature is enabled in the
      CRM, the available functions in the cluster management tools depend on
      the role and access rights assigned to a user.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><xref linkend="sec.ha.installation.setup.auto" xrefstyle="select:title"/>
    </term>
    <listitem>
     <para>
      For quick and easy cluster setup, use the bootstrap scripts
      <filename>sleha-init</filename> and <filename>sleha-join</filename> to
      get a one-node cluster up and running in a few minutes and to make
      other nodes join, respectively. Any options set during the bootstrap
      process can be modified later with the &yast; cluster module.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>&corosync; Unicast Mode</term>
    <listitem>
     <para>
      While multicast is still default, using unicast for the communication
      between nodes is now also supported. For more information, refer to
      <xref linkend="sec.ha.installation.setup.channels"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>&haweb; (&hawk;)</term>
    <listitem>
     <para>
      &hawk;'s functionality has been considerably extended. Now 
      you can configure global cluster properties, basic and advanced
      types of resources, constraints and resource monitoring. For detailed
      analysis of the cluster status, &hawk; generates a cluster report
      (<literal>hb_report</literal>). View the cluster history or
      explore potential failure scenarios with the simulator. For details,
      refer to <xref linkend="cha.ha.configuration.hawk"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><xref linkend="sec.ha.configuration.basics.resources.templates" xrefstyle="select:title"/>
    </term>
    <listitem>
     <para>
      To ease configuration of similar resources, all cluster management
      tools now let you define resource templates that can be referenced in
      primitives or certain types of constraints.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Virtualization and Cloud Integration</term>
    <listitem>
     <para>
      For placing resources based on load impact, the &hasi; now offers
      automatic detection of both the capacity of a node and the capacities a
      resource requires. The minimal requirements of a virtual machine (for
      example, the memory assigned to a Xen or KVM guest or the number of
      CPU cores) can be detected by a resource agent. Utilization attributes
      (used to define the requirements or capacity) will automatically be
      added to the CIB. For more information, refer to
      <xref
       linkend="sec.ha.configuration.basics.utilization"/>.
     </para>
<!--fate#310118-->
     <para>
      To protect a node's network connection from being overloaded by a
      large number of parallel Xen or KVM live migrations, a new global
      cluster property has been introduced: <literal>migration-limit</literal>.
      It allows you to limit the number of migration jobs that the TE may
      execute in parallel on a node. By default, it is set to
      <literal>-1</literal>, which means the number of parallel migrations is
      unlimited.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>conntrack Tools</term>
    <listitem>
     <para>
      To synchronize the connection status between cluster nodes, the &hasi;
      uses the
      <systemitem class="resource"
       >conntrack-tools</systemitem>.
      They allow interaction with the in-kernel Connection Tracking System
      for enabling <emphasis>stateful</emphasis> packet inspection for
      iptables. For more information, refer to
      <xref
       linkend="sec.ha.installation.setup.conntrackd"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Parallel SSH (<command>pssh</command>)</term>
    <listitem>
     <para>
      To execute commands on all cluster nodes without having to log in to
      each node, use <command>pssh</command>. For more information, refer to
      <xref linkend="sec.ha.troubleshooting.misc"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>crm resource secret</command>
    </term>
    <listitem>
     <para>
      To set passwords for &stonith; or other resources independent of
      <filename>cib.xml</filename>, use <command>crm resource
      secret</command>. For more information, refer to
      <xref linkend="sec.ha.config.crm.setpwd"
      />.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Samba Clustering </term>
    <listitem>
     <para>
      The CTDB functionality to join Active Directory Domains has been
      improved. For more information, refer to
      <xref linkend="sec.ha.samba.ad"
      />.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><xref linkend="cha.ha.rear" xrefstyle="select:title"/>
    </term>
    <listitem>
     <para>
      &rear; (Relax and Recover) is an administrator tool-set for creating
      disaster recovery images. The disaster recovery information can either
      be stored via the network or locally on hard disks, USB devices,
      DVD/CD-R, tape or similar. The backup data is stored on a network file
      system (NFS).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Quotas on OCFS2</term>
    <listitem>
     <para>
      To use quotas on OCFS2 file systems, create and mount the files system
      with the appropriate quota features or mount options, respectively:
      <literal>ursquota</literal> (quota for individual users) or
      <literal>grpquota</literal> (quota for groups).
     </para>
    </listitem>
   </varlistentry>
<!--taroth 2011-11-24: couldn't find any solid information about this
          (fate#309375: Support several block devices for shared-storage-based fencing
           still on needinfo-->
<!--<varlistentry>
    <term>Storage Protection</term>
    <listitem>
     <para>
      Development of a shared storage "poison pill" based fencing agent and daemon that can support 1 or 3 block devices..
     </para>
    </listitem>
   </varlistentry>-->
  </variablelist>
 </sect1>
</appendix>
