<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd"
[
  <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<!--taroth 2011-10-12: toms, please also have a look at dmuhamedagic's
 troubleshooting guide and either refer to it for more info (or include what's
 useful if the guide is not publically avaialable)-->
<!--taroth 2011-10-17: toms, please check any contents here for the
 following changes:
 * new deplyoment methods (installation as add-on or as appliance)
 * manual vs. automatic configuration 
 * apart from multicast, unicast is also supported now-->
<chapter id="cha.ha.troubleshooting">
 <title>Troubleshooting</title>
 <abstract>
  <para>
   Often, strange problems may occur that are not easy to understand
   (especially when starting to experiment with &ha;). However, there are
   several utilities that may be used to take a closer look at the &ha;
   internal processes. This chapter recommends various solutions.
  </para>
 </abstract>
 <sect1 id="sec.ha.troubleshooting.install">
  <title>Installation and First Steps</title>

  <para>
   Troubleshooting difficulties installing the packages or in bringing the
   cluster online.
  </para>

  <variablelist>
   <varlistentry>
    <term>Are the HA packages installed?</term>
    <listitem>
     <para>
      The packages needed for configuring and managing a cluster are
      included in the <literal>High Availability</literal> installation
      pattern, available with the &hasi;.
     </para>
     <para>
      Check if &hasi; is installed as an add-on to &sls; &productnumber; on
      each of the cluster nodes and if the <guimenu>High
      Availability</guimenu> pattern is installed on each of the machines as
      described in <xref linkend="sec.ha.installation.add-on"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Is the initial configuration the same for all cluster nodes? </term>
    <listitem>
     <para>
      In order to communicate with each other, all nodes belonging to the
      same cluster need to use the same <literal>bindnetaddr</literal>,
      <literal>mcastaddr</literal> and <literal>mcastport</literal> as
      described in <xref linkend="sec.ha.installation.setup.manual"/>.
     </para>
     <para>
      Check if the communication channels and options configured in
      <filename>/etc/corosync/corosync.conf</filename> are the same for all
      cluster nodes.
     </para>
     <para>
      In case you use encrypted communication, check if the
      <filename>/etc/corosync/authkey</filename> file is available on all
      cluster nodes.
     </para>
     <para>
      All <filename>corosync.conf</filename> settings with the exception of
      <literal>nodeid</literal> must be the same;
      <filename>authkey</filename> files on all nodes must be identical.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Does the Firewall allow communication via the
            <literal>mcastport</literal>?</term>
    <listitem>
     <para>
      If the mcastport used for communication between the cluster nodes is
      blocked by the firewall, the nodes cannot see each other. When
      configuring the initial setup with &yast; as described in
<!--taroth 2011-10-17: FIXME, chapter structure has changed: <xref linkend="sec.ha.installation.inst"/>-->
      , the firewall settings are usually automatically adjusted.
     </para>
     <para>
      To make sure the mcastport is not blocked by the firewall, check the
      settings in <filename>/etc/sysconfig/SuSEfirewall2</filename> on each
      node. Alternatively, start the &yast; firewall module on each cluster
      node. After clicking <menuchoice> <guimenu>Allowed Service</guimenu>
      <guimenu>Advanced</guimenu> </menuchoice>, add the mcastport to the
      list of allowed <guimenu>UDP Ports</guimenu> and confirm your changes.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Is &ais; started on each cluster node?</term>
    <listitem>
     <para>
      Check the &ais; status on each cluster node with
      <command>/etc/init.d/openais status</command>. In case &ais; is not
      running, start it by executing <command>/etc/init.d/openais
      start</command>.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 id="sec.ha.troubleshooting.log">
  <title>Logging</title>

  <variablelist>
   <varlistentry>
    <term>I defined monitoring but don't see any trace of them in
          the logs</term>
    <listitem>
     <para>
      The <systemitem class="daemon">lrmd</systemitem> daemon does not log
      recurring monitor operations (unless there was an error). Logging all
      recurring operatings would produce too much noise. Nevertheless, the
      recurring monitor operations are logged once an hour.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>I just get a failed message. Is it possible to get more
          information?</term>
    <listitem>
     <para>
      You may always add the <literal>--verbose</literal> parameter to your
      commands. If you do that multiple times, the debug output becomes very
      verbose. See <filename>/var/log/messages</filename> for useful hints.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>How can I get an overview of all my nodes and resources?</term>
    <listitem>
     <para>
      Use the <command>crm_mon</command> command. The following displays the
      resource operation history (option <option>-o</option>) and inactive
      resources (<option>-r</option>):
     </para>
     <screen>crm_mon -o -r</screen>
     <para>
      The display is refreshed when status changes (to cancel this press
      <keycombo> <keycap function="control"/> <keycap>C</keycap>
      </keycombo>.) An example could look like:
     </para>
     <example>
      <title>Stopped Resources</title>
      <screen>Refresh in 10s...

============
Last updated: Mon Jan 19 08:56:14 2009
Current DC: d42 (d42)
3 Nodes configured.
3 Resources configured.
============

Online: [ d230 d42 ]
OFFLINE: [ clusternode-1 ]

Full list of resources:

Clone Set: o2cb-clone
         Stopped: [  o2cb:0 o2cb:1o2cb:2 ]
Clone Set: dlm-clone
         Stopped [ dlm:0 dlm:1 dlm:2 ]
mySecondIP      (ocf::heartbeat:IPaddr):        Stopped

Operations:
* Node d230:
   aa: migration-threshold=1000000
    + (5) probe: rc=0 (ok)
    + (37) stop: rc=0 (ok)
    + (38) start: rc=0 (ok)
    + (39) monitor: interval=15000ms rc=0 (ok)
* Node d42:
   aa: migration-threshold=1000000
    + (3) probe: rc=0 (ok)
    + (12) stop: rc=0 (ok)</screen>
     </example>
     <para>
      First get your node online and after that, check your resources and
      operations.
     </para>
     <para>
      The <citetitle>Configuration Explained</citetitle> PDF covers three
      different recovery types in the <citetitle>How Does the Cluster
      Interpret the OCF Return Codes?</citetitle> section. It is available
      from available from
      <xref
              linkend="vle.ha.configuration.basics.more.clusterlabs.doc"
              xrefstyle="select: title nopage"/>.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 id="sec.ha.troubleshooting.resource">
  <title>Resources</title>

  <variablelist>
   <varlistentry>
    <term>How can I clean up my resources?</term>
    <listitem>
     <para>
      Use the following commands :
     </para>
     <screen>crm resource list
crm resource cleanup <replaceable>rscid</replaceable> [<replaceable>node</replaceable>]</screen>
     <para>
      If you leave out the node, the resource is cleaned on all nodes. More
      information can be found in
      <xref
              linkend="sec.ha.manual_config.cleanup"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>How can I list my currently known resources?</term>
    <listitem>
     <para>
      Use the command <command>crm resource list</command> to display your
      current resources.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>I configured a resource, but it always fails. Why?</term>
    <listitem>
     <para>
      To check an OCF script use <command>ocf-tester</command>, for
      instance:
     </para>
     <screen>ocf-tester -n ip1 -o ip=<replaceable>YOUR_IP_ADDRESS</replaceable> \
  /usr/lib/ocf/resource.d/heartbeat/IPaddr</screen>
     <para>
      Use <option>-o</option> multiple times for more parameters. The list
      of required and optional parameters can be obtained by running
      <command>crm</command> <option>ra</option> <option>info</option>
      <replaceable>AGENT</replaceable>, for example:
     </para>
     <screen>crm ra info ocf:heartbeat:IPaddr</screen>
     <para>
      Before running ocf-tester, make sure the resource is not managed by
      the cluster.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why are the resources will not fail over and are no
          errors?</term>
    <listitem>
     <para>
      If your cluster is a two node cluster, killing one node will leave the
      remaining node without quorum. Unless you set the
      <option>no-quorum-policy</option> property to
      <literal>ignore</literal> nothing is ever going to happen. Hence,
      remember that for two-node clusters you need:
     </para>
     <screen>property no-quorum-policy="ignore"</screen>
     <para>
      Another possibility is that the killed node is considered unclean.
      Then it is necessary to fence it. If the stonith resource is not
      operational or even doesn't exist, the remaining node will just sit
      around waiting for the fencing to happen in vain. The fencing timeouts
      are typically high, so it may take quite a while to see any obvious
      sign of problems (if ever).
     </para>
     <para>
      Yet another possible explanation is that a resource is simply not
      allowed to run on this node. That may be due to a failure which
      happened in the past and which was not <quote>cleaned</quote>. Or it
      may be due to an earlier administrative action, i.e. a location
      constraint with a negative score. Such a location constraint is for
      instance inserted by the <command>crm resource migrate</command>
      command.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why can I never say where my resource will run?</term>
    <listitem>
     <para>
      If there are no location constraints for a resource, its placement is
      subject to an (almost) random node choice. You are well advised to
      always express a preferred node for resources. Of course, that doesn't
      mean that <emphasis>all</emphasis> resources need location
      preferences. One suffices for a set of related (collocated) resources.
      A node preference looks like this:
     </para>
     <screen>location rsc-prefers-node1 rsc 100: node1</screen>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 id="sec.ha.troubleshooting.stonith">
  <title>&stonith; and Fencing</title>

  <variablelist>
   <varlistentry>
    <term>Why cannot my &stonith; resource be started?</term>
    <listitem>
     <para>
      Start (or enable) operation includes checking the status of the
      device. If the device is not ready at that point in time, the
      &stonith; resource will fail to start.
     </para>
     <para>
      At the same time the &stonith; plugin will be asked to produce a host
      list. If this list is empty, there is not much point in running a
      &stonith; resource which cannot shoot anything. One particularly mean
      way of ending up with an empty list is when the list returned contains
      just the node on which the stonith resource is to be started. Namely,
      it is not allowed for a node to shoot itself, so to avoid any possible
      future misunderstandings _this_ node name is filtered out from the
      host list. If what remains is nothing, there you go.
     </para>
     <para>
      Accordingly, if you want to use a single-host management device such
      as any kind of those lights-out devices then make sure that the
      stonith resource is _not_ allowed to run on the node which it is
      supposed to be able to fence. Just use an infinitely negative location
      node preference (constraint). Mind, the cluster will manage and move
      the stonith resource to another place where it can start, but not
      before yelling at you. Some may find that slighting, so better to
      avoid it.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why does fencing not happen, although I have this &stonith; resource?</term>
    <listitem>
     <para>
      Each stonith resource must provide a host list. This list may be
      inserted by hand in the &stonith; resource configuration or retrieved
      from the device itself, for instance from outlet names. That depends
      on the nature of the &stonith; plugin. At any rate, when asked, a
      &stonith; plugin must somehow provide this list. Now, the whole point
      of the host list is for <systemitem>stonithd</systemitem> to find out
      which &stonith; resource can fence the target node. Only in case the
      node appears in the list it is assumed that this stonith instance can
      shoot (fence) the node.
     </para>
     <para>
      In case <systemitem>stonithd</systemitem> does not find the node in
      any of the host lists of &stonith; resources which are running there,
      it will ask around (that is <systemitem>stonithd</systemitem>
      instances on other nodes) if there is anybody who can fence the node.
      If there is nobody able to do that, this ends in a fencing request
      timeout at the originating node. The real cause may not be very
      obvious. Couple that with exceptionally long and unwieldy node names,
      which seems to be a very popular corporate tactic in self-deception,
      and you have a great recipe for a mess.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why does my &stonith;resource fails occasionally?</term>
    <listitem>
     <para>
      Power management devices can be squeamish. In particular, if you try
      to exercise them too much for their liking. So, space out generously
      the monitor operations. Given that fencing is necessary only once in a
      while (and hopefully never), checking the device status once a few
      hours is more than enough.
     </para>
     <para>
      Also, some of these devices may refuse to talk to more than one party
      at the same time. This may be a problem if you keep a terminal or
      browser session open while the cluster tries to test the status.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 id="sec.ha.troubleshooting.misc">
  <title>Miscelleneous</title>

  <variablelist>
   <varlistentry>
<!-- FATE#311413 -->
    <term>How can I run commands on all cluster nodes?</term>
    <listitem>
     <para>
      Use the command <command>pssh</command> for this task. Install
      <systemitem class="resource">pssh</systemitem> if you have not done
      yet. Create a file (for example <filename>hosts.txt</filename>) where
      you collect all your IP addresses or hostnames you want to visit. Make
      sure you can log in with <command>ssh</command> for each hostnames in
      your <filename>hosts.txt</filename> file. If everything is correctly
      prepared, execute <command>pssh</command> and use the
      <filename>hosts.txt</filename> file (option <option>-h</option>) and
      the interactive mode (option <option>-i</option>) as shown in this
      example:
     </para>
     <screen>pssh -i -h hosts.txt "ls -l /corosync/*.conf"
[1] 08:28:32 [SUCCESS] root@&wsII;.&exampledomain;
-rw-r--r-- 1 root root 1480 Nov 14 13:37 /etc/corosync/corosync.conf
[2] 08:28:32 [SUCCESS] root@&wsIIIip;
-rw-r--r-- 1 root root 1480 Nov 14 13:37 /etc/corosync/corosync.conf</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>What is the state of my cluster?</term>
    <listitem>
     <para>
      To check the current state of your cluster, use one of the programs
      <literal>crm_mon</literal> or <command>crm</command>
      <option>status</option>. This displays the current DC as well as all
      the nodes and resources known by the current node.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why cannot see several nodes of my cluster do not see each other?</term>
    <listitem>
     <para>
      There could be several reasons:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Look first in the configuration file
        <filename>/etc/corosync/corosync.conf</filename> and check if the
        multicast address is the same for every node in the cluster (look in
        the <literal>interface</literal> section with the key
        <literal>mcastaddr</literal>.)
       </para>
      </listitem>
      <listitem>
       <para>
        Check your firewall settings.
       </para>
      </listitem>
      <listitem>
       <para>
        Check if your switch supports multicast addresses
       </para>
      </listitem>
      <listitem>
       <para>
        Check if the connection between your nodes is broken. Most often,
        this is the result of a badly configured firewall. This also may be
        the reason for a <emphasis>split brain</emphasis> condition, where
        the cluster is partitioned.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Why cannot an ocfs2 device be mounted?</term>
    <listitem>
     <para>
      Check <filename>/var/log/messages</filename> if there is the following
      line:
     </para>
     <screen>Jan 12 09:58:55 clusternode2 lrmd: [3487]: info: RA output: (o2cb:1:start:stderr) 2009/01/12_09:58:55 
  ERROR: Could not load ocfs2_stackglue
Jan 12 16:04:22 clusternode2 modprobe: FATAL: Module ocfs2_stackglue not found.</screen>
     <para>
      In this case the kernel module <filename>ocfs2_stackglue.ko</filename>
      is missing. Install the package
      <filename>ocfs2-kmp-default</filename>,
      <filename>ocfs2-kmp-pae</filename> or
      <filename>ocfs2-kmp-xen</filename> depending on the installed kernel.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
<!-- FATE#310174 -->
    <term>How can I create a report with an analysis of all my cluster nodes?</term>
    <listitem>
     <para>
      Use the tool <command>hb_report</command> to create a report. Usually
      run <command>hb_report</command> with the following command:
     </para>
     <screen><command
>hb_report</command> -f 0:00 -n &exampleclient; -n &exampleclientII;</screen>
     <para>
      The previous command extracts all information since 0 am on the hosts
      &exampleclient; and &exampleclientII;. After the command was
      successful, you will find an tar.bz2 archive in the current directory.
     </para>
     <warning>
      <title>Remove Sensitive Information</title>
      <para>
       The <command>hb_report</command> tool tries to remove any sensitive
       information from the CIB and the peinput files, however, it can not
       do everything. If you have more sensitive information, supply
       additional patterns yourself. The logs and the crm_mon, ccm_tool, and
       crm_verify output are <emphasis>not</emphasis> sanitized.
      </para>
      <para>
       Before publishing your data to mailinglists or other parties, first
       look into the archive to protect your data and remove any information
       you do not want to expose.
      </para>
     </warning>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 id="sec.ha.troubleshooting.moreinfo">
  <title>Fore More Information</title>

  <para>
   For additional information about high availability on Linux, including
   configuring cluster resources and managing and customizing a &ha;
   cluster, see
   <ulink
    url="http://clusterlabs.org/wiki/Documentation"/>.
  </para>
 </sect1>
</chapter>
