<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd" [
 <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
 <!ENTITY % entities SYSTEM "entity-decl.ent">
 %entities;
]>
<chapter id="cha.ha.configuration.hawk">
 <title>Managing Cluster Resources with the Web Interface</title>
 <abstract>
  <para>In addition to the <command>crm</command> command line tool and the
   &hbgui; the &hasi; also comes with the &hawk;, a Web-based user
   interface for management tasks. It allows you to monitor and administer your
   Linux cluster also from non-Linux machines. It is also an ideal solution in
   case your system does not provide or allow a graphical user interface.</para>
  <para>
   <remark>taroth 2010-03-04: tserong, I guess the hawk package needs to be
    installed on each node I want to access via the Web-browser? when accessing
    any of the cluster nodes via hawk from another machine (outside the cluster), it is
    enough to have a web browser installed?</remark>The Web interface is included in the <systemitem class="resource"
    >hawk</systemitem> package.</para>
 </abstract>
 <sect1>
  <title>&hawk;&mdash;Overview</title>
  <para>&hawk; is intended to run on each node in your cluster. To access
   the administration options, you need to log in to a cluster.</para>
  <note>
   <title>Authentication: <systemitem class="username">hacluster</systemitem>
    User and <systemitem class="groupname">haclient</systemitem> Group</title>
   <para>To log in to the cluster from the &hawk;, the respective user must
    be a member of the <systemitem class="groupname">haclient</systemitem>
    group. The installation creates a linux user named
     <systemitem>hacluster</systemitem> which is member of the <systemitem
     class="groupname">haclient</systemitem> group.</para>
   <para>Before using the &hawk;, either set a password for the
     <systemitem>hacluster</systemitem> user or create a new user which is
    member of the <systemitem class="groupname">haclient</systemitem>
    group.</para>
   <para> Do this on every node you will connect to with the &hawk;. </para>
  </note>
 </sect1>
 
 <!--(green == good and running, red ==
bad, yellow == transition, grey == intentionally out of the picture)-->
 <!--Greetings All,
 
 
 This will give you a web-based GUI with a display roughly
 analagous to crm_mon, in terms of status of cluster resources.
 It will show you running/dead/standby nodes, and the resources
 (clones, groups and primitives) running on those nodes.
 
 It does not yet provide information about failed resources or
 nodes, other than the fact that they are not running.
 
 Display of nodes and resources is collapsible (collapsed by
 default), but if something breaks while you are looking at it,
 the display will expand to show the broken nodes and/or
 resources.
 
 Hawk is intended to run on each node in your cluster. You
 can then access it by pointing your web browser at the IP
 address of any cluster node, or the address of any IPaddr(2)
 resource you may have configured.
 
 Minimally, to see it in action, you will need the following
 packages and their dependencies (names per openSUSE/SLES):
 
 - ruby
 - rubygem-rails-2_3
 - rubygem-gettext_rails
 
 Once you've got those installed, run the following command:
 
 # hawk/script/server
 
 Then, point your browser at http://your-server:3000/ to see
 the status of your cluster.
 
 Ultimately, hawk is intended to be installed and run as a
 regular system service via /etc/init.d/hawk. To do this,
 you will need the following additional packages:
 
 - lighttpd
 - lighttpd-mod_magnet
 - ruby-fcgi
 - rubygem-rake
 
 Then, try the following, but READ THE MAKEFILE FIRST!
 "make install" (and the rest of the build system for that
 matter) is frightfully primitive at the moment:
 
 # make
 # sudo make install
 # /etc/init.d/hawk start
 
 Then, point your browser at http://your-server:4444/ to see
 the status of your cluster.
 
 Assuming you've read this far, what next?
 
 - In the very near future (but probably not next week,
 because I'll be busy at linux.conf.au) you can expect to
 see further documentation and roadmap info up on the
 clusterlabs.org wiki.
 
 - Immediate goal is to obtain feature parity with crm_mon
 (completing status display, adding error/failure messages).
 
 - Various pieces of scaffolding need to be put in place (login
 page, access via HTTPS, clean up build/packaging, theming,
 etc.)
 
 - After status display, the following major areas of
 funcionality are:
 - Basic operator tasks (stop/start/migrate resource,
 standby/online node, etc.)
 - Explore failure scenarios (shadow CIB magic to see
 what would happen if a node/resource failed).
 - Ability to actually configure resources and nodes.
 
 Please direct comments, feedback, questions, etc. to
 tserong [at] novell and/or the Pacemaker mailing list.
 
 Thank you for your attention.
 
 Regards,
 
 Tim -->
</chapter>
