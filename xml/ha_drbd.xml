<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd" [
 <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
 <!ENTITY % entities SYSTEM "entity-decl.ent">
 %entities;
]>
<!--
 TODOs:
* Fate #305039 
* DocComment #8052
-->
<chapter id="cha.ha.drbd">
 <title>Distributed Replicated Block Device (DRBD)</title>
 <abstract>
  <para>
   DRBD allows you to create a mirror of two block devices that are located
   at two different sites across an IP network. When used with &ais;, DRBD
   supports distributed high-availability Linux clusters. This chapter shows
   you how to install and setup DRBD.
  </para>
 </abstract>
 <sect1 id="sec.ha.drbd.overview">
  <title>Conceptual Overview</title>
  <!-- Missing some -->
  <para>
   DRBD replicates data on the primary device to the secondary device 
   in a way that ensures that both copies of the data remain identical.
   Think of it as a networked RAID&nbsp;1.
   It mirrors data in real time, so its replication occurs continuously.
   Applications need not to know that in fact their data is stored on 
   different disks.
<!--When using a
   cluster aware file system such as ocfs2, it is also possible to run both
   nodes as primary devices.-->
  </para>
  
  <important>
   <title>Unencrypted Data</title>
   <para>
    The data traffic between mirrors is not encrypted. For secure data
    exchange, you should deploy a virtual private network (VPN) solution for
    the connection.
   </para>
  </important>
  
  <para>DRBD is a Linux kernel module and sits between the I/O scheduler
   and the filesystem.<remark>insert nice graphic</remark> To
   communicate with DRBD, users use the high-level command 
   <command>drbdadm</command>. For maximum flexibility DRBD comes with
   the low-level tool <command>drbdsetup</command>.
  </para>

  <para>DRBD allows you to use any block device supported by Linux,
   usually it is one of these:</para>
  <itemizedlist>
   <listitem>
    <para>a partition on your hard disk</para>
   </listitem>
   <listitem>
    <para>software RAID</para>
   </listitem>
   <listitem>
    <para>Logical Volume Manager (LVM)</para>
   </listitem>
   <listitem>
    <para>Enterprise Volume Management System (EVMS)</para>
   </listitem>
  </itemizedlist>
  
  
  <para>
   By default, DRBD uses the TCP port 7780 and above for communications
   between DRBD nodes. Make sure that your firewall does not prevent
   communication on this port.
  </para>

<!--
  
  <para>
   You must set up the DRBD devices before creating file systems on them.
   Everything pertaining to user data should be done solely via the
   <filename>/dev/drbd&lt;n&gt;</filename> device and not on the raw device,
   as DRBD uses the last 128 MB of the raw device for metadata. Make sure to
   create file systems only on the <filename>/dev/drbd&lt;n&gt;</filename>
   device and not on the raw device.
  </para>
  <para>
   For example, if the raw device is 1024 MB in size, the DRBD device has
   only 896 MB available for data, with 128 MB hidden and reserved for the
   metadata. Any attempt to access the space between 896 MB and 1024 MB fails
   because it is not available for user data.
  </para>-->
 </sect1>
 <sect1 id="sec.ha.drbd.install">
  <title>Installing DRBD Services</title>

  <para>
   To install the needed packages for DRBD, install
   the &hasi; Add-On product on both &sls; machines in your networked
   cluster as described in <xref
    linkend="part.install"/>. Installing
   &hasi; also installs the DRBD program files.
  </para>

  <para>
   If you do not need the complete cluster stack but just want to use
   DRBD, <xref linkend="tab.ha.drbd.rpmfiles"/> contains a list of
   all RPM packages for DRBD. During the last version the
   <systemitem>drbd</systemitem> package was split into seperate
   packages.
  </para>
  
  <table id="tab.ha.drbd.rpmfiles">
   <title>DRBD RPM Packages</title>
   <tgroup cols="2">
    <thead>
     <row>
      <entry>
       <para>Filename</para>
      </entry>
      <entry>
       <para>Explanation</para>
      </entry>
     </row>
    </thead>
    <tbody>
     <row>
      <entry>
       <para><systemitem class="resource">drbd</systemitem></para>
      </entry>
      <entry>
       <para>Convenience package, split into other</para>
      </entry>
     </row>
     <row>
      <entry>
       <para><systemitem class="resource">drbd-bash-completion</systemitem></para>
      </entry>
      <entry>
       <para>Programmable bash completion support for drbdadm</para>
      </entry>
     </row>
     <row>
      <entry>
       <para><systemitem class="resource">drbd-heartbeat</systemitem></para>
      </entry>
      <entry>
       <para>Heartbeat resource agent for DRBD (only needed for
        Heartbeat)</para>
      </entry>
     </row>
     <row>
      <entry>
       <para><systemitem class="resource">drbd-kmp-default</systemitem></para>
      </entry>
      <entry>
       <para>Kernel module for DRBD (needed)</para>
      </entry>
     </row>
     <row>
      <entry>
       <para><systemitem class="resource">drbd-kmp-xen</systemitem></para>
      </entry>
      <entry>
       <para>Xen kernel module for DRBD</para>
      </entry>
     </row>
     <row>
      <entry>
       <para><systemitem class="resource">drbd-udev</systemitem></para>
      </entry>
      <entry>
       <para>udev integration scripts for DRBD, managing symlinks to
        DRBD devices in <filename>/dev/drbd/by-res</filename> and
         <filename>/dev/drbd/by-disk</filename></para>
      </entry>
     </row>
     <row>
      <entry>
       <para><systemitem class="resource">drbd-utils</systemitem></para>
      </entry>
      <entry>
       <para>Management utilities for DRBD (needed)</para>
      </entry>
     </row>
     <row>
      <entry>
       <para><systemitem class="resource">drbd-pacemaker</systemitem></para>
      </entry>
      <entry>
       <para>Pacemaker resource agent for DRBD</para>
      </entry>
     </row>
     <row>
      <entry>
       <para><systemitem class="resource">drbd-xen</systemitem></para>
      </entry>
      <entry>
       <para>Xen block device management script for DRBD</para>
      </entry>
     </row>
     <row>
      <entry>
       <para><systemitem class="resource">yast2-drbd</systemitem></para>
      </entry>
      <entry>
       <para>&yast; DRBD Configuration (recommended)</para>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </table>

 </sect1>
 
 <sect1 id="sec.ha.drbd.configure">
  <title>Configuring the DRBD Service</title>
  <note>
   <para>
    The following procedure uses the server names &wsI; and &wsII;, and the
    cluster resource name r0. It sets up &wsI; as the primary node. Make
    sure to modify the instructions to use your own node and file names.
   </para>
  </note>
  
  <para>Before you start configuring DRBD, make sure your
  block devices in your Linux nodes are ready and paritioned (if
  needed). The following procedure assumes you
  have two nodes, &wsI; and &wsII;, and they use the TCP port 7780. Make
  sure this port is open in your firewall.</para>
  <para>To setup DRBD manually, proceed as follows:</para>
   
  
  <procedure id="step.drbd.configure">
   <title>Manually Configure DRBD</title>
   <step>
    <para>Login as user &rootuser;.</para>
   </step>
   <step>
    <para>Change DRBD's configuration files:</para>
    <substeps>
     <step>
      <para>Open the file <filename>/etc/drbd.conf</filename> and insert
       the following lines, if not available:</para>
      <screen>include "drbd.d/global_common.conf";
include "drbd.d/*.res";</screen>
      <para>Beginning with DRBD 8.3 the configuration file is split into
       separate files, located under the directory
        <filename>/etc/drbd.d</filename>.</para>
     </step>
     <step>
      <para>Open the file
       <filename>/etc/drbd.d/global_common.conf</filename>. It contains
       already soome pre-definied values. Go to the
       <literal>startup</literal> section and insert these lines:</para>
      <screen>startup {
    # wfc-timeout degr-wfc-timeout outdated-wfc-timeout
    # wait-after-sb;
    wfc-timeout 1;
    degr-wfc-timeout 1;
}</screen>
      <para>These options are used to reduce the timeouts when booting,
       see <ulink url="http://www.drbd.org/users-guide-emb/re-drbdconf.html"/>
       for more details.</para>
     </step>
     <step>
      <para>Create the file <filename>/etc/drbd.d/r0.res</filename>,
       change the lines to your situation, and save it:</para>
      <screen>resource r0 { <co id="co.drbd.config.r0"/>
  device /dev/drbd_r0 minor 0; <co id="co.drbd.config.device"/>
  disk /dev/sda1; <co id="co.drbd.config.disk"/>
  meta-disk internal; <co id="co.drbd.config.meta-disk"/>
  on &wsI; { <co id="co.drbd.config.resname"/>
    address  &subnetI;.10:7780; <co id="co.drbd.config.address"/>
  }
  on &wsII; { <xref linkend="co.drbd.config.resname"
   xrefstyle="selec:nopage"/>
    address &subnetI;.11:7780; <xref linkend="co.drbd.config.address"
   xrefstyle="selec:nopage"/>
  }
  syncer {
    rate  7M; <co id="co.drbd.config.syncer-rate"/>
  }
}</screen>
      <calloutlist>
       <callout arearefs="co.drbd.config.r0">
        <para>Name of the resource. It is recommended to use resource
         names like <systemitem>r0</systemitem>,
          <systemitem>r1</systemitem>, etc.</para>
       </callout>
       <callout arearefs="co.drbd.config.device">
        <para>The device name for DRBD and its minor number. It is
         recommended to start with <filename>/dev/drbd</filename> and
         append your resource name (<systemitem>r0</systemitem> in this
         case).</para>
       </callout>
       <callout arearefs="co.drbd.config.disk">
        <para>The device that is replicated between nodes. Note, in
         this example the devices are the same on both nodes. If you
         need different devices, move the <literal>disk</literal>
         parameter into the <literal>on</literal> section.</para>
       </callout>
       <callout arearefs="co.drbd.config.meta-disk">
        <para>The meta-disk parameter usually contains the value
         <literal>internal</literal>, but it is possible to specify an
         explict device to hold the meta data. See 
         <ulink url="http://www.drbd.org/users-guide-emb/ch-internals.html#s-metadata"/>
         for more information.
        </para>
       </callout>
       <callout arearefs="co.drbd.config.resname">
        <para>The <literal>on</literal> section contains the hostname of the node</para>
       </callout>
       <callout arearefs="co.drbd.config.address">
        <para>The IP address and port number of the respective node.
         Each resource needs an individual port, usually starting with
         7780.</para>
       </callout>
       <callout arearefs="co.drbd.config.syncer-rate">
        <para>The syncronization rate. Set it to one third of your bandwith.
         It only limits the resyncronization, not the mirroring.</para>
       </callout>
      </calloutlist>
     </step>
   </substeps>
   </step>
   <step>
    <para>Check the syntax of your configuration file(s). If the
     following command returns an error, verify your files:</para>
    <screen>drbdadm dump all</screen>
   </step>
   <step>
    <para>Copy the DRBD configuration files to the other node:</para>
    <screen>scp /etc/drbd.conf &wsII;:/etc/
scp /etc/drbd.d/*  &wsII;:/etc/drbd.d/</screen>
   </step>
   <step>
    <para>Initialize the meta data on <emphasis>both</emphasis> systems
     by entering the following on each node. </para>
    <screen>drbdadm -- --ignore-sanity-checks create-md r0
rcdrbd start</screen>
     <para>If your disk contains already a filesystem that you do not
      need anymore, destroy the filesystem structure with the following
      command and repeat this step:</para>
    <screen>dd if=/dev/zero of=/dev/sdb1 count=10000</screen>
   </step>
   <step>
    <para>Watch the DRBD status by entering the following on each node:</para>
    <screen>rcdrbd status</screen>
    <para>You should get something like this:</para>
    <screen><?dbsuse-fo font-size="6pt"
?>drbd driver loaded OK; device status:
version: 8.3.7 (api:88/proto:86-91)
GIT-hash: ea9e28dbff98e331a62bcbcc63a6135808fe2917 build by phil@fat-tyre, 2010-01-13 17:17:27
m:res  cs         ro                   ds                         p  mounted  fstype
0:r0   Connected  Secondary/Secondary  Inconsistent/Inconsistent  C</screen>
     <!-- Add short explanation? -->
   </step>
   <step>
    <para>Start the resync process on your intented primary node (&wsI;
     in this case):</para>
    <screen>drbdadm -- --overwrite-data-of-peer primary r0</screen>
   </step>
   <step>
    <para>Check the status again with <command>rcdrbd status</command>
    and you get:</para>
    <screen><?dbsuse-fo font-size="6pt"?>...
m:res  cs         ro                 ds                 p  mounted  fstype
0:r0   Connected  Primary/Secondary  UpToDate/UpToDate  C</screen>
    <para>The status in the <literal>ds</literal> row (disk status) must
    be UpToDate on both nodes.</para>
   </step>
   <step>
    <para>Set &wsI; as primary node:</para>
    <screen>drbdadm primary r0</screen>
   </step>
   <step>
    <para>Create your filesystem on top of your DRBD device, for
    example:</para>
    <screen>mkfs.ext3 /dev/drbd_r0</screen>
   </step>
   <step>
    <para>Mount the filesystem and use it:</para>
    <screen>mount /dev/drbd_r0 /mnt/</screen>
   </step>
  </procedure>
  
  <!-- toms 2010-02-05: The YaST DRBD module does not save the
       configuration. It seems the include statement (introduced
       in drbd v8.3) is not known or it is broken.
       See bnc#473143
  -->
  <!--
   <para>To use &yast; to configure DRBD, proceed as follows:</para>
  
  <procedure id="step.drbd.configure__">
   <title>Using &yast; to Configure DRBD</title>
   <step>
    <para>
     Start &yast; and select the configuration module
     <menuchoice><guimenu>Miscellaneous</guimenu><guimenu>drbd</guimenu></menuchoice>.
    </para>
   </step>
   <step>
    <para>
     In <menuchoice><guimenu>Start-up
     Configuration</guimenu><guimenu>Booting</guimenu></menuchoice> select
     <guimenu>On</guimenu> to start drbd always at boot time.
    </para>
   </step>
   <step>
    <para>
     If you need to configure more than one replicated resource, select
     <guimenu>Global Configuration</guimenu>. The input field <guimenu>Minor
     Count</guimenu> selects how many different drbd resources may be
     configured without restarting the computer.
    </para>
   </step>
   <step>
    <para>
     The actual configuration of the resource is done in <guimenu>Resource
     Configuration</guimenu>. Press <guimenu>Add</guimenu> to create a new
     resource. The following parameters have to be set:
    </para>
    <informaltable>
     <tgroup cols="2">
      <tbody>
       <row>
        <entry>
         <para>
          <guimenu>Resource Name</guimenu>
         </para>
        </entry>
        <entry>
         <para>
          The name of the resource, often called <literal>r0</literal>.
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          <guimenu>Name</guimenu>
         </para>
        </entry>
        <entry>
         <para>
          The hostname of the relevant node.
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          <guimenu>Address:Port</guimenu>
         </para>
        </entry>
        <entry>
         <para>
          The IP address and port number of the respective node.
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          <guimenu>Device</guimenu>
         </para>
        </entry>
        <entry>
         <para>
          The device that holds the replicated data on the respective node.
          Use this device to create file systems and mount operations.
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          <guimenu>Disk</guimenu>
         </para>
        </entry>
        <entry>
         <para>
          The device that is replicated between both nodes.
         </para>
        </entry>
       </row>
       <row>
        <entry>
         <para>
          <guimenu>Meta-disk</guimenu>
         </para>
        </entry>
        <entry>
         <para>
          The <guimenu>Meta-disk</guimenu> is either set to the value
          <literal>internal</literal> or specifies an explicit device
          extended by an index to hold the meta data needed by drbd.
         </para>
         <para>
          When using <literal>internal</literal>, the last 128 MB of the
          replicated device are used to store the meta data.
         </para>
         <para>
          A real device may also be used for multiple drbd resources. For
          example, if your <guimenu>Meta-Disk</guimenu> is
          <filename>/dev/sda6[0]</filename> for the first resource, you may
          use <filename>/dev/sda6[1]</filename> for the second resource.
          However, there must be at least 128 MB space for each resource
          available on this disk.
         </para>
        </entry>
       </row>
      </tbody>
     </tgroup>
    </informaltable>
    <para>
     All of these options are explained in the examples in the
     <filename>/usr/share/doc/packages/drbd/drbd.conf</filename> file and in
     the man page of <command>drbd.conf(5)</command>.
    </para>
   </step>
   <step>
    <para>
     Copy the <filename>/etc/drbd.conf</filename> file to the
     <filename>/etc/drbd.conf</filename> location on the secondary server
     (node 2).
    </para>
<screen>
scp /etc/drbd.conf &lt;node 2&gt;:/etc
</screen>
   </step>
   <step>
    <para>
     Initialize and start the DRBD service on both systems by entering the
     following on each node:
    </para>
<!-\- TODO: do we need drbdadm create-md r0 ? -\->
<!-\- it does not work without the create-md for me -\->
<screen>
drbdadm create-md r0
rcdrbd start
</screen>
   </step>
   <step>
    <para>
     Configure <filename>node1</filename> as the primary node by entering
     the following on <filename>node1</filename>:
    </para>
<screen>
drbdsetup /dev/drbd0 primary &#x2d;&#x2d;overwrite-data-of-peer
</screen>
   </step>
   <step>
    <para>
     Check the DRBD service status by entering the following on each node:
    </para>
<screen>
rcdrbd status
</screen>
    <para>
     Before proceeding, wait until the block devices on both nodes are fully
     synchronized. Repeat the <command>rcdrbd status</command> command to
     follow the synchronization progress.
    </para>
   </step>
   <step>
    <para>
     After the block devices on both nodes are fully synchronized, format
     the DRBD device on the primary with a file system such as reiserfs. Any
     Linux file system can be used. For example, enter
    </para>
<screen>
mkfs.reiserfs -f /dev/drbd0 
</screen>
    <important>
     <para>
      Always use the <filename>/dev/drbd&lt;n&gt;</filename> name in the
      command, not the actual <filename>/dev/disk</filename> device name.
     </para>
    </important>
   </step>
  </procedure>-->
 </sect1>
 <sect1 id="sec.ha.drbd.test">
  <title>Testing the DRBD Service</title>

  <para>
   If the install and configuration procedures worked as expected, you are
   ready to run a basic test of the DRBD functionality. This test also helps
   with understanding how the software works.
  </para>

  <procedure id="proc.drbd.test">
   <step>
    <para>
     Test the DRBD service on node 1.
    </para>
    <substeps>
     <step>
      <para>
       Open a terminal console, then log in as
       <systemitem>root</systemitem>.
      </para>
     </step>
     <step>
      <para>
       Create a mount point on node 1, such as
       <filename>/srv/r0mount</filename>.
      </para>
<screen>
mkdir -p /srv/r0mount
</screen>
     </step>
     <step>
      <para>
       Mount the <command>drbd</command> device.
      </para>
<screen>
mount -o rw /dev/drbd0 /srv/r0mount
</screen>
     </step>
     <step>
      <para>
       Create a file from the primary node.
      </para>
<screen>
touch /srv/r0mount/from_node1
</screen>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     Test the DRBD service on node 2.
    </para>
    <substeps>
     <step>
      <para>
       Open a terminal console, then log in as
       <systemitem>root</systemitem>.
      </para>
     </step>
     <step>
      <para>
       Dismount the disk on node 1.
      </para>
<screen>
umount /srv/r0mount
</screen>
     </step>
     <step>
      <para>
       Downgrade the DRBD service on node 1 by typing the following command
       on node 1:
      </para>
<screen>
drbdadm secondary r0
</screen>
     </step>
     <step>
      <para>
       On node 2, promote the DRBD service to primary.
      </para>
<screen>
drbdadm primary r0
</screen>
     </step>
     <step>
      <para>
       On node 2, check to see if node 2 is primary.
      </para>
<screen>
rcdrbd status
</screen>
     </step>
     <step>
      <para>
       On node 2, create a mount point such as
       <filename>/srv/r0mount</filename>.
      </para>
<screen>
mkdir /srv/r0mount
</screen>
     </step>
     <step>
      <para>
       On node 2, mount the DRBD device.
      </para>
<screen>
mount -o rw /dev/drbd0 /srv/r0mount
</screen>
     </step>
     <step>
      <para>
       Verify that the file you created on node 1 is viewable.
      </para>
<screen>
ls /srv/r0mount
</screen>
      <para>
       The <filename>/srv/r0mount/from_node1</filename> file should be
       listed.
      </para>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     If the service is working on both nodes, the DRBD setup is complete.
    </para>
   </step>
   <step>
    <para>
     Set up node 1 as the primary again.
    </para>
    <substeps>
     <step>
      <para>
       Dismount the disk on node 2 by typing the following command on node
       2:
      </para>
<screen>
umount /srv/r0mount
</screen>
     </step>
     <step>
      <para>
       Downgrade the DRBD service on node 2 by typing the following command
       on node 2:
      </para>
<screen>
drbdadm secondary r0
</screen>
     </step>
     <step>
      <para>
       On node 1, promote the DRBD service to primary.
      </para>
<screen>
drbdadm primary r0
</screen>
     </step>
     <step>
      <para>
       On node 1, check to see if node 1 is primary.
      </para>
<screen>
rcdrbd status
</screen>
     </step>
    </substeps>
   </step>
   <step>
    <para>
     To get the service to automatically start and fail over if the server
     has a problem, you can set up DRBD as a high availability service with
     &ais;. For information about installing and configuring &ais; for &sle;
     11 see <xref linkend="part.config"/>.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 id="sec.ha.drbd.trouble">
  <title>Troubleshooting DRBD</title>

  <para>
   The drbd setup involves many different components and problems may arise
   from different sources. The following sections cover several common
   scenarios and recommends various solutions.
  </para>

  <sect2 id="sec.ha.drbd.trouble.config">
   <title>Configuration</title>
   <para>
    If the initial <systemitem>drbd</systemitem> setup does not work as
    expected, there is probably something wrong with your configuration.
   </para>
   <para>
    To get information about the configuration:
   </para>
   <procedure>
    <step>
     <para>
      Open a terminal console, then log in as <systemitem>root</systemitem>.
     </para>
    </step>
    <step>
     <para>
      Test the configuration file by running <command>drbdadm</command> with
      the <command>-d</command> option. Enter
     </para>
<screen>
drbdadm -d adjust r0
</screen>
     <para>
      In a dry run of the <command>adjust</command> option,
      <command>drbdadm</command> compares the actual configuration of the
      DRBD resource with your DRBD configuration file, but it does not
      execute the calls. Review the output to make sure you know the source
      and cause of any errors.
     </para>
    </step>
    <step>
     <para>
      If there are errors in the <filename>drbd.conf</filename> file,
      correct them before continuing.
     </para>
    </step>
    <step>
     <para>
      If the partitions and settings are correct, run
      <command>drbdadm</command> again without the <command>-d</command>
      option.
     </para>
<screen>
drbdadm adjust r0
</screen>
     <para>
      This applies the configuration file to the DRBD resource.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 id="sec.ha.drbd.hostnames">
   <title>Hostnames</title>
   <para>
    For DRBD, hostnames are case sensitive (<systemitem>Node0</systemitem>
    would be a different host than <systemitem>node0</systemitem>).
   </para>
   <para>
    If you have several network devices and want to use a dedicated network
    device, the hostname will likely not resolve to the used ip address. In
    this case, use the parameter <literal>disable-ip-verification</literal>.
   </para>
  </sect2>

  <sect2 id="sec.ha.drbd.port">
   <title>TCP Port 7788</title>
   <para>
    If your system is unable to connect to the peer, this might be a problem
    with your local firewall. By default, DRBD uses the TCP port 7788 to
    access the other node. Make sure that this port is accessible on both
    nodes.
   </para>
  </sect2>

  <sect2>
   <title>DRBD Devices Broken after Reboot</title>
   <para>
    In cases when DRBD does not know which of the real devices holds the
    latest data, it changes to a split brain condition. In this case, the
    respective DRBD subsystems come up as secondary and do not connect to
    each other. In this case, the following message is written to
    <filename>/var/log/messages</filename>:
   </para>
<screen>Split-Brain detected, dropping connection!</screen>
   <para>
    To resolve this situation, enter the following on the node which has
    data to be discarded:
   </para>
<screen>drbdadm secondary r0 
drbdadm -- --discard-my-data connect r0</screen>
   <para>
    On the node which has the latest data enter the following:
   </para>
<screen>drbdadm connect r0</screen>
  </sect2>
 </sect1>
 <sect1 id="sec.ha.drbd.more">
  <title>Additional Information</title>

  <para>
   The following open source resources are available for DRBD:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     The project home page <ulink url="http://www.drbd.org"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     <ulink url="http://clusterlabs.org/wiki/DRBD_HowTo_1.0"/> by the Linux
     Pacemaker Cluster Stack Project.
    </para>
   </listitem>
   <listitem>
    <para>
     The following man pages for DRBD are available in the distribution:
    </para>
    <simplelist>
     <member><command>drbd(8)</command>
     </member>
     <member><command>drbddisk(8)</command>
     </member>
     <member><command>drbdsetup(8)</command>
     </member>
     <member><command>drbdadm(8)</command>
     </member>
     <member><command>drbd.conf(5)</command>
     </member>
    </simplelist>
   </listitem>
   <listitem>
    <para>
     Find a commented example configuration for DRBD at
     <filename>/usr/share/doc/packages/drbd/drbd.conf</filename>
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
</chapter>
