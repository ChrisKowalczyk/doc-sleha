<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//Novell//DTD NovDoc XML V1.0//EN" "novdocx.dtd"
[
  <!ENTITY % NOVDOC.DEACTIVATE.IDREF "INCLUDE">
  <!ENTITY % entities SYSTEM "entity-decl.ent">
  %entities;
]>
<chapter id="cha.ha.start">
 <title>Getting Started</title>
 <para>
  In the following, learn about the system requirements and which
  preparations to take before installing the &hasi;. Find a short overview
  of the basic steps to install and set up a cluster.
 </para>
 <sect1 id="sec.ha.start.hwreq">
  <title>Hardware Requirements</title>

  <para>
   The following list specifies hardware requirements for a cluster based on
   &productnamereg;. These requirements represent the minimum hardware
   configuration. Additional hardware might be necessary, depending on how
   you intend to use your cluster.
  </para>

  <itemizedlist>
   <listitem>
    <para>
     1 to 32 Linux servers with software as specified in
     <xref linkend="sec.ha.start.swreq"/>. The servers do not require
     identical hardware (memory, disk space, etc.).
    </para>
   </listitem>
   <listitem>
    <para>
     At least two TCP/IP communication media. Cluster nodes use multicast
     for communication so the network equipment must support multicasting.
     The communication media should support a data rate of 100 Mbit/s or
     higher. Preferably, the Ethernet channels should be bonded.
    </para>
   </listitem>
   <listitem>
    <para>
     Optional: A shared disk subsystem connected to all servers in the
     cluster from where it needs to be accessed.
    </para>
   </listitem>
   <listitem>
    <para>
     A &stonith; mechanism. &stonith; is an acronym for <quote>Shoot the
     other node in the head</quote>. A &stonith; device is a power switch
     which the cluster uses to reset nodes that are thought to be dead or
     behaving in a strange manner. Resetting non-heartbeating nodes is the
     only reliable way to ensure that no data corruption is performed by
     nodes that hang and only appear to be dead.
    </para>
    <para>
     For more information, refer to <xref linkend="cha.ha.fencing"/>.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
<?dbfo-need height="10em"?>
 <sect1 id="sec.ha.start.swreq">
  <title>Software Requirements</title>

  <para>
   Ensure that the following software requirements are met:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     &slsreg; &productnumber; with all available online updates installed on
     all nodes that will be part of the cluster.
    </para>
   </listitem>
   <listitem>
    <para>
     &productname; &productnumber; including all available online updates
     installed on all nodes that will be part of the cluster.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 id="sec.ha.start.diskreq">
  <title>Shared Disk System Requirements</title>

  <para>
   A shared disk system (Storage Area Network, or SAN) is recommended for
   your cluster if you want data to be highly available. If a shared disk
   subsystem is used, ensure the following:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     The shared disk system is properly set up and functional according to
     the manufacturer&rsquo;s instructions.
    </para>
   </listitem>
   <listitem>
    <para>
     The disks contained in the shared disk system should be configured to
     use mirroring or RAID to add fault tolerance to the shared disk system.
     Hardware-based RAID is recommended. Host-based software RAID is not
     supported for all configurations.
    </para>
   </listitem>
   <listitem>
    <para>
     If you are using iSCSI for shared disk system access, ensure that you
     have properly configured iSCSI initiators and targets.
    </para>
   </listitem>
   <listitem>
    <para>
     When using DRBD to implement a mirroring RAID system that distributes
     data across two machines, make sure to only access the replicated
     <remark>taroth
     2011-04-28: comment by ulrich windl: replicating device? DEVs, which is
     correct?</remark>
     device. Use the same (bonded) NICs that the rest of the cluster uses to
     leverage the redundancy provided there.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 id="sec.ha.start.prep">
  <title>Preparations</title>

  <para>
   Prior to installation of the &hasi;, execute the following preparatory
   steps:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Configure hostname resolution and use static host information by
     editing the <filename>/etc/hosts</filename> file on each server in the
     cluster. For more information, see the <citetitle>&sls;</citetitle>
     &admin;, available at
     <ulink
      url="http://www.novell.com/documentation"/>. Refer to
     chapter <citetitle>Basic Networking &gt; Configuring Hostname and
     DNS</citetitle>.
    </para>
    <para>
     It is essential that members of the cluster are able to find each other
     by name. If the names are not available, internal cluster communication
     will fail.
    </para>
   </listitem>
   <listitem>
    <para>
     Configure time synchronization by making cluster nodes synchronize to a
     time server outside the cluster. For more information, see the
     <citetitle>&sls;</citetitle> &admin;, available at
     <ulink
      url="http://www.novell.com/documentation"/>. Refer to
     chapter <citetitle>Time Synchronization with NTP</citetitle>.
    </para>
    <para>
     The cluster nodes will use the time server as their time
     synchronization source.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 id="sec.ha.start.oview">
  <title>Overview: Installing and Setting Up a Cluster</title>

  <para>
   After the preparations are done, the following basic steps are necessary
   to install and set up a cluster with &productnamereg;:
  </para>

  <orderedlist>
   <listitem>
    <para>
     Installation of &slsreg; and &productnamereg; as add-on on top of
     &sls;. For detailed information, see
     <xref
      linkend="sec.ha.installation.inst"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="sec.ha.installation.setup" xrefstyle="select:title"/>
    </para>
   </listitem>
   <listitem>
    <para>
     <xref linkend="sec.ha.installation.start" xrefstyle="select:title"/>
    </para>
   </listitem>
   <listitem>
    <para>
     Configuring global cluster options and adding cluster resources.
    </para>
    <para>
     Both can be done either with a graphical user interface (GUI) or with
     command line tools. For detailed information, see
     <xref
      linkend="cha.ha.configuration.gui"/> or
     <xref
      linkend="cha.ha.manual_config"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     To protect your data from possible corruption by means of fencing and
     &stonith;, make sure to configure &stonith; devices as resources. For
     detailed information, see <xref linkend="cha.ha.fencing"/>.
    </para>
   </listitem>
  </orderedlist>

  <para>
   Depending on your requirements, you may also want to configure the
   following file system and storage-related components for your cluster:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Create file systems on a shared disk (Storage Area Network, SAN). If
     necessary, configure those file systems as cluster resources.
    </para>
   </listitem>
   <listitem>
    <para>
     If you need cluster-aware file systems, use OCFS2.
    </para>
   </listitem>
   <listitem>
    <para>
     To allow the cluster to manage shared storage with Logical Volume
     Manager, use cLVM, which is a set of clustering extensions to LVM.
    </para>
   </listitem>
   <listitem>
    <para>
     To protect your data integrity, implement storage protection by using
     fencing mechanisms and by ensuring exclusive storage access.
    </para>
   </listitem>
   <listitem>
    <para>
     If needed, make use of data replication with DRBD.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   For detailed information, see <xref linkend="part.storage"/>.
  </para>
 </sect1>
</chapter>
